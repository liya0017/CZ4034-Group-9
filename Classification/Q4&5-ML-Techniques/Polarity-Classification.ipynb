{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d104707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1291610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install contractions\n",
    "# !pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20cc9b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>1376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>1769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          full_text\n",
       "label              \n",
       "Negative       1376\n",
       "Positive       1769"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "df = df[['full_text', 'Sentiment Analysis (Label)']]\n",
    "df.rename(columns = {'Sentiment Analysis (Label)': 'label'}, inplace = True)\n",
    "df = df[df['label'] != 'Neutral']\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa9877d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polarity</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          full_text\n",
       "polarity           \n",
       "0              1376\n",
       "1              1769"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_mapping = {'Negative': 0, 'Positive': 1}\n",
    "df['polarity'] = df['label'].map(label_mapping)\n",
    "df_polarity = df[['full_text','polarity']]\n",
    "df_polarity.groupby('polarity').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e44316a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thinking about a conspiraboomer paying some CO...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@aja9696 @civillibertari2 @POTUS That's litera...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@POTUS I have a question Mr Presidente  If I g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@ziggystar18 @corybernardi Ironically, yes, be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@dysclinic And many become worse after covid v...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  polarity\n",
       "0  Thinking about a conspiraboomer paying some CO...         0\n",
       "1  @aja9696 @civillibertari2 @POTUS That's litera...         1\n",
       "2  @POTUS I have a question Mr Presidente  If I g...         0\n",
       "3  @ziggystar18 @corybernardi Ironically, yes, be...         1\n",
       "4  @dysclinic And many become worse after covid v...         0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_polarity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b3ac6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"eval.csv\")\n",
    "test_df = test_df[['full_text', 'Sentiment Analysis (Label)']]\n",
    "test_df.rename(columns = {'Sentiment Analysis (Label)': 'label'}, inplace = True)\n",
    "test_df = test_df[test_df['label'] != 'Neutral']\n",
    "test_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1151bcbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polarity</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          full_text\n",
       "polarity           \n",
       "0               250\n",
       "1               264"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_mapping = {'Negative': 0, 'Positive': 1}\n",
    "test_df['polarity'] = test_df['label'].map(label_mapping)\n",
    "polarity_test_df = test_df[['full_text','polarity']]\n",
    "polarity_test_df.groupby('polarity').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ef3752",
   "metadata": {},
   "source": [
    "### Preprocessing Tweets\n",
    "\n",
    "We will be using these commonly used ways to pre-process tweets\n",
    "\n",
    "1. Expand contractions\n",
    "2. Map emojis into its word meaning\n",
    "3. Remove mentions(@), hashtags(#), punctuations and numbers as we prioritise sentiment from the text\n",
    "4. Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d35cad5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i cannot believe it be of the clock i will be home soon party_popper\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import contractions\n",
    "import emoji\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    # Step 1: Expand contractions\n",
    "    text = contractions.fix(text)\n",
    "    \n",
    "    # Step 2: Map emojis into its word meaning\n",
    "    text = emoji.demojize(text)\n",
    "\n",
    "    # Step 3: Remove mentions, hashtags, numbers and links\n",
    "    pattern = r'@[A-Za-z0-9_]+|#[A-Za-z0-9]+|\\d+|https?://\\S+|[^\\w\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    # put text to lowercase\n",
    "    text = text.lower() \n",
    "    \n",
    "    # Step 4: Lemmatize words\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    words = text.split()\n",
    "    words = [wordnet_lemmatizer.lemmatize(word, pos=\"v\") for word in words]\n",
    "    text = ' '.join(words)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Example usage:\n",
    "tweet = \"@username #happybirthday! I can't believe it's 5 o'clock. 123 I'll be home soon https://facebook.com ðŸŽ‰\"\n",
    "cleaned_tweet = clean_text(tweet)\n",
    "print(cleaned_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b83fa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polarity['clean_text'] = df_polarity['full_text'].apply(clean_text)\n",
    "polarity_test_df['clean_text'] = polarity_test_df['full_text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b67c5458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47674e4",
   "metadata": {},
   "source": [
    "### Subjectivity Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43c6dfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def validation(pipeline):\n",
    "    \n",
    "    print(pipeline)\n",
    "    \n",
    "    # Initialize lists to store evaluation metrics\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "\n",
    "    # K-Fold Cross Validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(df_polarity)):\n",
    "            X_train_fold, X_val_fold = df_polarity['clean_text'].iloc[train_index], df_polarity['clean_text'].iloc[val_index]\n",
    "            y_train_fold, y_val_fold = df_polarity['polarity'].iloc[train_index], df_polarity['polarity'].iloc[val_index]\n",
    "\n",
    "            pipeline.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "            # Get predictions on validation fold\n",
    "            predictions = pipeline.predict(X_val_fold)\n",
    "\n",
    "            # Compute accuracy for this fold\n",
    "            fold_accuracy = accuracy_score(y_val_fold, predictions)\n",
    "            accuracies.append(fold_accuracy)\n",
    "            \n",
    "            # Compute precision, recall, and F1-score for this fold\n",
    "            fold_report = classification_report(y_val_fold, predictions, output_dict=True)\n",
    "\n",
    "            # Append precision, recall, and F1-score to respective lists\n",
    "            precisions.append(fold_report['weighted avg']['precision'])\n",
    "            recalls.append(fold_report['weighted avg']['recall'])\n",
    "            f1_scores.append(fold_report['weighted avg']['f1-score'])\n",
    "\n",
    "    # Calculate the mean accuracy, precision, recall, and F1-score across all folds\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_precision = np.mean(precisions)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    mean_f1_score = np.mean(f1_scores)\n",
    "    \n",
    "    # Test against test set\n",
    "    pipeline.fit(df_polarity['clean_text'], df_polarity['polarity'])\n",
    "    \n",
    "    # Get predictions on test set\n",
    "    predictions = pipeline.predict(polarity_test_df['clean_text'])\n",
    "    \n",
    "    # Compute accuracy for test set\n",
    "    test_accuracy = accuracy_score(polarity_test_df['polarity'], predictions)\n",
    "\n",
    "    # Compute precision, recall, and F1-score for test set\n",
    "    test_report = classification_report(polarity_test_df['polarity'], predictions, output_dict=True)\n",
    "\n",
    "    print(\"Mean K-Fold Accuracy:\", mean_accuracy)\n",
    "    print(\"Mean K-Fold Precision:\", mean_precision)\n",
    "    print(\"Mean K-Fold Recall:\", mean_recall)\n",
    "    print(\"Mean K-Fold F1-Score:\", mean_f1_score)\n",
    "    \n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "    print(\"Test Precision:\", test_report['weighted avg']['precision'])\n",
    "    print(\"Test Recall:\", test_report['weighted avg']['recall'])\n",
    "    print(\"Test F1-Score:\", test_report['weighted avg']['f1-score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0790d9fd",
   "metadata": {},
   "source": [
    "### Pipelines using unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dfddd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define count vectorizer pipeline for Logistic Regression\n",
    "lr_cv_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(tokenizer=word_tokenize)),  # Use NLTK's word_tokenize function\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Define count vectorizer pipeline for Support Vector Machine (SVM)\n",
    "svm_cv_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(tokenizer=word_tokenize)),  # Use NLTK's word_tokenize function\n",
    "    ('classifier', SVC())\n",
    "])\n",
    "\n",
    "# Define count vectorizer pipeline for Naive Bayes\n",
    "nb_cv_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(tokenizer=word_tokenize)),  # Use NLTK's word_tokenize function\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Define count vectorizer pipeline for Random Forest\n",
    "rf_cv_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(tokenizer=word_tokenize)),  # Use NLTK's word_tokenize function\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Define TF-IDF vectorizer pipeline for Logistic Regression\n",
    "lr_tfidf_pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize)),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Define TF-IDF vectorizer pipeline for Support Vector Machine (SVM)\n",
    "svm_tfidf_pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize)),\n",
    "    ('classifier', SVC())\n",
    "])\n",
    "\n",
    "# Define TF-IDF vectorizer pipeline for Naive Bayes\n",
    "nb_tfidf_pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize)),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Define TF-IDF vectorizer pipeline for Random Forest\n",
    "rf_tfidf_pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize)),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f73d4421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('vectorizer',\n",
      "                 CountVectorizer(tokenizer=<function word_tokenize at 0x000001D31662AAC0>)),\n",
      "                ('classifier', LogisticRegression(max_iter=1000))])\n",
      "Mean K-Fold Accuracy: 0.7036565977742448\n",
      "Mean K-Fold Precision: 0.7026243155986036\n",
      "Mean K-Fold Recall: 0.7036565977742448\n",
      "Mean K-Fold F1-Score: 0.7023988833002877\n",
      "Test Accuracy: 0.669260700389105\n",
      "Test Precision: 0.6692723246714242\n",
      "Test Recall: 0.669260700389105\n",
      "Test F1-Score: 0.6687685063909293\n",
      "\n",
      "Pipeline(steps=[('vectorizer',\n",
      "                 CountVectorizer(tokenizer=<function word_tokenize at 0x000001D31662AAC0>)),\n",
      "                ('classifier', SVC())])\n",
      "Mean K-Fold Accuracy: 0.6922098569157392\n",
      "Mean K-Fold Precision: 0.6914550077352666\n",
      "Mean K-Fold Recall: 0.6922098569157392\n",
      "Mean K-Fold F1-Score: 0.6871883101623848\n",
      "Test Accuracy: 0.6575875486381323\n",
      "Test Precision: 0.6594247063529582\n",
      "Test Recall: 0.6575875486381323\n",
      "Test F1-Score: 0.6552323639488311\n",
      "\n",
      "Pipeline(steps=[('vectorizer',\n",
      "                 CountVectorizer(tokenizer=<function word_tokenize at 0x000001D31662AAC0>)),\n",
      "                ('classifier', MultinomialNB())])\n",
      "Mean K-Fold Accuracy: 0.7090620031796503\n",
      "Mean K-Fold Precision: 0.7116978045281624\n",
      "Mean K-Fold Recall: 0.7090620031796503\n",
      "Mean K-Fold F1-Score: 0.7010195695032888\n",
      "Test Accuracy: 0.6400778210116731\n",
      "Test Precision: 0.647110831811552\n",
      "Test Recall: 0.6400778210116731\n",
      "Test F1-Score: 0.632913003934644\n",
      "\n",
      "Pipeline(steps=[('vectorizer',\n",
      "                 CountVectorizer(tokenizer=<function word_tokenize at 0x000001D31662AAC0>)),\n",
      "                ('classifier', RandomForestClassifier())])\n",
      "Mean K-Fold Accuracy: 0.6880763116057234\n",
      "Mean K-Fold Precision: 0.6918704828543577\n",
      "Mean K-Fold Recall: 0.6880763116057234\n",
      "Mean K-Fold F1-Score: 0.6769032568883482\n",
      "Test Accuracy: 0.6381322957198443\n",
      "Test Precision: 0.6476966613153384\n",
      "Test Recall: 0.6381322957198443\n",
      "Test F1-Score: 0.6289435099421067\n",
      "\n",
      "Pipeline(steps=[('vectorizer',\n",
      "                 TfidfVectorizer(tokenizer=<function word_tokenize at 0x000001D31662AAC0>)),\n",
      "                ('classifier', LogisticRegression(max_iter=1000))])\n",
      "Mean K-Fold Accuracy: 0.7106518282988871\n",
      "Mean K-Fold Precision: 0.7115927228046237\n",
      "Mean K-Fold Recall: 0.7106518282988871\n",
      "Mean K-Fold F1-Score: 0.7047918059404064\n",
      "Test Accuracy: 0.669260700389105\n",
      "Test Precision: 0.6720522122426689\n",
      "Test Recall: 0.669260700389105\n",
      "Test F1-Score: 0.6665264808271043\n",
      "\n",
      "Pipeline(steps=[('vectorizer',\n",
      "                 TfidfVectorizer(tokenizer=<function word_tokenize at 0x000001D31662AAC0>)),\n",
      "                ('classifier', SVC())])\n",
      "Mean K-Fold Accuracy: 0.7201907790143084\n",
      "Mean K-Fold Precision: 0.7211328432169456\n",
      "Mean K-Fold Recall: 0.7201907790143084\n",
      "Mean K-Fold F1-Score: 0.7151659876397811\n",
      "Test Accuracy: 0.688715953307393\n",
      "Test Precision: 0.6893815277493345\n",
      "Test Recall: 0.688715953307393\n",
      "Test F1-Score: 0.6877781938361852\n",
      "\n",
      "Pipeline(steps=[('vectorizer',\n",
      "                 TfidfVectorizer(tokenizer=<function word_tokenize at 0x000001D31662AAC0>)),\n",
      "                ('classifier', MultinomialNB())])\n",
      "Mean K-Fold Accuracy: 0.646422893481717\n",
      "Mean K-Fold Precision: 0.7199052898838441\n",
      "Mean K-Fold Recall: 0.646422893481717\n",
      "Mean K-Fold F1-Score: 0.5845249950340888\n",
      "Test Accuracy: 0.5797665369649806\n",
      "Test Precision: 0.6458843501645058\n",
      "Test Recall: 0.5797665369649806\n",
      "Test F1-Score: 0.5149953834993075\n",
      "\n",
      "Pipeline(steps=[('vectorizer',\n",
      "                 TfidfVectorizer(tokenizer=<function word_tokenize at 0x000001D31662AAC0>)),\n",
      "                ('classifier', RandomForestClassifier())])\n",
      "Mean K-Fold Accuracy: 0.6855325914149443\n",
      "Mean K-Fold Precision: 0.6879388811427379\n",
      "Mean K-Fold Recall: 0.6855325914149443\n",
      "Mean K-Fold F1-Score: 0.6748197134479749\n",
      "Test Accuracy: 0.6517509727626459\n",
      "Test Precision: 0.6616216787938229\n",
      "Test Recall: 0.6517509727626459\n",
      "Test F1-Score: 0.643572295482418\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv_pipelines = [lr_cv_pipeline, svm_cv_pipeline, nb_cv_pipeline, rf_cv_pipeline,\n",
    "                lr_tfidf_pipeline, svm_tfidf_pipeline, nb_tfidf_pipeline, rf_tfidf_pipeline]\n",
    "\n",
    "for pipeline in cv_pipelines:\n",
    "    validation(pipeline)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0b11d4",
   "metadata": {},
   "source": [
    "### Pipelines using n-grams(1,2) : Unigrams + Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8feca4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CountVectorizer pipeline for Logistic Regression with n-grams (1, 2)\n",
    "lr_cv_ngram_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(tokenizer=word_tokenize, ngram_range=(1, 2))),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Define CountVectorizer pipeline for Support Vector Machine (SVM) with n-grams (1, 2)\n",
    "svm_cv_ngram_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(tokenizer=word_tokenize, ngram_range=(1, 2))),\n",
    "    ('classifier', SVC())\n",
    "])\n",
    "\n",
    "# Define CountVectorizer pipeline for Naive Bayes with n-grams (1, 2)\n",
    "nb_cv_ngram_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(tokenizer=word_tokenize, ngram_range=(1, 2))),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Define CountVectorizer pipeline for Random Forest with n-grams (1, 2)\n",
    "rf_cv_ngram_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(tokenizer=word_tokenize, ngram_range=(1, 2))),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "# Define TF-IDF vectorizer pipeline for Logistic Regression with n-grams (1, 2)\n",
    "lr_tfidf_ngram_pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize, ngram_range=(1, 2))),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Define TF-IDF vectorizer pipeline for Support Vector Machine (SVM) with n-grams (1, 2)\n",
    "svm_tfidf_ngram_pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize, ngram_range=(1, 2))),\n",
    "    ('classifier', SVC())\n",
    "])\n",
    "\n",
    "# Define TF-IDF vectorizer pipeline for Naive Bayes with n-grams (1, 2)\n",
    "nb_tfidf_ngram_pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize, ngram_range=(1, 2))),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Define TF-IDF vectorizer pipeline for Random Forest with n-grams (1, 2)\n",
    "rf_tfidf_ngram_pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize, ngram_range=(1, 2))),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3cc4d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('vectorizer',\n",
      "                 CountVectorizer(ngram_range=(1, 2),\n",
      "                                 tokenizer=<function word_tokenize at 0x000001D31662AAC0>)),\n",
      "                ('classifier', LogisticRegression(max_iter=1000))])\n",
      "Mean K-Fold Accuracy: 0.7236883942766295\n",
      "Mean K-Fold Precision: 0.7226287155551465\n",
      "Mean K-Fold Recall: 0.7236883942766295\n",
      "Mean K-Fold F1-Score: 0.7219093869972267\n",
      "Test Accuracy: 0.7217898832684825\n",
      "Test Precision: 0.7217965366083615\n",
      "Test Recall: 0.7217898832684825\n",
      "Test F1-Score: 0.7215714657412097\n",
      "\n",
      "Pipeline(steps=[('vectorizer',\n",
      "                 CountVectorizer(ngram_range=(1, 2),\n",
      "                                 tokenizer=<function word_tokenize at 0x000001D31662AAC0>)),\n",
      "                ('classifier', SVC())])\n",
      "Mean K-Fold Accuracy: 0.6966613672496026\n",
      "Mean K-Fold Precision: 0.6971693511455634\n",
      "Mean K-Fold Recall: 0.6966613672496026\n",
      "Mean K-Fold F1-Score: 0.6903543302216981\n",
      "Test Accuracy: 0.669260700389105\n",
      "Test Precision: 0.6736851775569656\n",
      "Test Recall: 0.669260700389105\n",
      "Test F1-Score: 0.6654801257991576\n",
      "\n",
      "Pipeline(steps=[('vectorizer',\n",
      "                 CountVectorizer(ngram_range=(1, 2),\n",
      "                                 tokenizer=<function word_tokenize at 0x000001D31662AAC0>)),\n",
      "                ('classifier', MultinomialNB())])\n",
      "Mean K-Fold Accuracy: 0.7049284578696343\n",
      "Mean K-Fold Precision: 0.7211952930869943\n",
      "Mean K-Fold Recall: 0.7049284578696343\n",
      "Mean K-Fold F1-Score: 0.6875235142993462\n",
      "Test Accuracy: 0.6595330739299611\n",
      "Test Precision: 0.6825242141867902\n",
      "Test Recall: 0.6595330739299611\n",
      "Test F1-Score: 0.6449789999131031\n",
      "\n",
      "Pipeline(steps=[('vectorizer',\n",
      "                 CountVectorizer(ngram_range=(1, 2),\n",
      "                                 tokenizer=<function word_tokenize at 0x000001D31662AAC0>)),\n",
      "                ('classifier', RandomForestClassifier())])\n",
      "Mean K-Fold Accuracy: 0.6842607313195549\n",
      "Mean K-Fold Precision: 0.695776841545363\n",
      "Mean K-Fold Recall: 0.6842607313195549\n",
      "Mean K-Fold F1-Score: 0.6667495985996162\n",
      "Test Accuracy: 0.6361867704280155\n",
      "Test Precision: 0.6549138383055131\n",
      "Test Recall: 0.6361867704280155\n",
      "Test F1-Score: 0.6206347027642873\n",
      "\n",
      "Pipeline(steps=[('vectorizer',\n",
      "                 TfidfVectorizer(ngram_range=(1, 2),\n",
      "                                 tokenizer=<function word_tokenize at 0x000001D31662AAC0>)),\n",
      "                ('classifier', LogisticRegression(max_iter=1000))])\n",
      "Mean K-Fold Accuracy: 0.7144674085850556\n",
      "Mean K-Fold Precision: 0.7237416286737701\n",
      "Mean K-Fold Recall: 0.7144674085850556\n",
      "Mean K-Fold F1-Score: 0.702494754731965\n",
      "Test Accuracy: 0.6848249027237354\n",
      "Test Precision: 0.6956860091355102\n",
      "Test Recall: 0.6848249027237354\n",
      "Test F1-Score: 0.6783697035987736\n",
      "\n",
      "Pipeline(steps=[('vectorizer',\n",
      "                 TfidfVectorizer(ngram_range=(1, 2),\n",
      "                                 tokenizer=<function word_tokenize at 0x000001D31662AAC0>)),\n",
      "                ('classifier', SVC())])\n",
      "Mean K-Fold Accuracy: 0.7103338632750397\n",
      "Mean K-Fold Precision: 0.7245600872567473\n",
      "Mean K-Fold Recall: 0.7103338632750397\n",
      "Mean K-Fold F1-Score: 0.6950501802513942\n",
      "Test Accuracy: 0.688715953307393\n",
      "Test Precision: 0.7024501751909613\n",
      "Test Recall: 0.688715953307393\n",
      "Test F1-Score: 0.6812102258263938\n",
      "\n",
      "Pipeline(steps=[('vectorizer',\n",
      "                 TfidfVectorizer(ngram_range=(1, 2),\n",
      "                                 tokenizer=<function word_tokenize at 0x000001D31662AAC0>)),\n",
      "                ('classifier', MultinomialNB())])\n",
      "Mean K-Fold Accuracy: 0.6114467408585055\n",
      "Mean K-Fold Precision: 0.7246953996566666\n",
      "Mean K-Fold Recall: 0.6114467408585055\n",
      "Mean K-Fold F1-Score: 0.514397906122683\n",
      "Test Accuracy: 0.566147859922179\n",
      "Test Precision: 0.6905294664377196\n",
      "Test Recall: 0.566147859922179\n",
      "Test F1-Score: 0.4697062533829272\n",
      "\n",
      "Pipeline(steps=[('vectorizer',\n",
      "                 TfidfVectorizer(ngram_range=(1, 2),\n",
      "                                 tokenizer=<function word_tokenize at 0x000001D31662AAC0>)),\n",
      "                ('classifier', RandomForestClassifier())])\n",
      "Mean K-Fold Accuracy: 0.6763116057233705\n",
      "Mean K-Fold Precision: 0.6790991578579372\n",
      "Mean K-Fold Recall: 0.6763116057233705\n",
      "Mean K-Fold F1-Score: 0.6645752114074344\n",
      "Test Accuracy: 0.6206225680933852\n",
      "Test Precision: 0.6318367468289982\n",
      "Test Recall: 0.6206225680933852\n",
      "Test F1-Score: 0.608073339179711\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ngrams_pipelines = [lr_cv_ngram_pipeline, svm_cv_ngram_pipeline, nb_cv_ngram_pipeline, rf_cv_ngram_pipeline,\n",
    "                   lr_tfidf_ngram_pipeline, svm_tfidf_ngram_pipeline, nb_tfidf_ngram_pipeline, rf_tfidf_ngram_pipeline]\n",
    "\n",
    "for pipeline in ngrams_pipelines:\n",
    "    validation(pipeline)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5e5150",
   "metadata": {},
   "source": [
    "### Pipelines using n-grams(2,2) : Bigrams (Tried, but perfromance is low so it is not considered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19b1753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define CountVectorizer pipeline for Logistic Regression with bigrams only\n",
    "# lr_cv_ngram_pipeline = Pipeline([\n",
    "#     ('vectorizer', CountVectorizer(tokenizer=word_tokenize, ngram_range=(2, 2))),\n",
    "#     ('classifier', LogisticRegression(max_iter=1000))\n",
    "# ])\n",
    "\n",
    "# # Define CountVectorizer pipeline for Support Vector Machine (SVM) with bigrams only\n",
    "# svm_cv_ngram_pipeline = Pipeline([\n",
    "#     ('vectorizer', CountVectorizer(tokenizer=word_tokenize, ngram_range=(2, 2))),\n",
    "#     ('classifier', SVC())\n",
    "# ])\n",
    "\n",
    "# # Define CountVectorizer pipeline for Naive Bayes with bigrams only\n",
    "# nb_cv_ngram_pipeline = Pipeline([\n",
    "#     ('vectorizer', CountVectorizer(tokenizer=word_tokenize, ngram_range=(2, 2))),\n",
    "#     ('classifier', MultinomialNB())\n",
    "# ])\n",
    "\n",
    "# # Define CountVectorizer pipeline for Random Forest with bigrams only\n",
    "# rf_cv_ngram_pipeline = Pipeline([\n",
    "#     ('vectorizer', CountVectorizer(tokenizer=word_tokenize, ngram_range=(2, 2))),\n",
    "#     ('classifier', RandomForestClassifier())\n",
    "# ])\n",
    "\n",
    "# # Define TF-IDF vectorizer pipeline for Logistic Regression with bigrams only\n",
    "# lr_tfidf_ngram_pipeline = Pipeline([\n",
    "#     ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize, ngram_range=(2, 2))),\n",
    "#     ('classifier', LogisticRegression(max_iter=1000))\n",
    "# ])\n",
    "\n",
    "# # Define TF-IDF vectorizer pipeline for Support Vector Machine (SVM) with bigrams only\n",
    "# svm_tfidf_ngram_pipeline = Pipeline([\n",
    "#     ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize, ngram_range=(2, 2))),\n",
    "#     ('classifier', SVC())\n",
    "# ])\n",
    "\n",
    "# # Define TF-IDF vectorizer pipeline for Naive Bayes with bigrams only\n",
    "# nb_tfidf_ngram_pipeline = Pipeline([\n",
    "#     ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize, ngram_range=(2, 2))),\n",
    "#     ('classifier', MultinomialNB())\n",
    "# ])\n",
    "\n",
    "# # Define TF-IDF vectorizer pipeline for Random Forest with bigrams only\n",
    "# rf_tfidf_ngram_pipeline = Pipeline([\n",
    "#     ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize, ngram_range=(2, 2))),\n",
    "#     ('classifier', RandomForestClassifier())\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c68f2c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngrams_pipelines = [lr_cv_ngram_pipeline, svm_cv_ngram_pipeline, nb_cv_ngram_pipeline, rf_cv_ngram_pipeline,\n",
    "#                    lr_tfidf_ngram_pipeline, svm_tfidf_ngram_pipeline, nb_tfidf_ngram_pipeline, rf_tfidf_ngram_pipeline]\n",
    "\n",
    "# for pipeline in ngrams_pipelines:\n",
    "#     validation(pipeline)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb485109",
   "metadata": {},
   "source": [
    "### Pipelines using n-grams(2,3) : Bigrams + Trigrams (Tried, but perfromance is low so it is not considered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aece0910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define CountVectorizer pipeline for Logistic Regression with bigrams and trigrams\n",
    "# lr_cv_ngram_pipeline = Pipeline([\n",
    "#     ('vectorizer', CountVectorizer(tokenizer=word_tokenize, ngram_range=(2, 3))),\n",
    "#     ('classifier', LogisticRegression(max_iter=1000))\n",
    "# ])\n",
    "\n",
    "# # Define CountVectorizer pipeline for Support Vector Machine (SVM) with bigrams and trigrams\n",
    "# svm_cv_ngram_pipeline = Pipeline([\n",
    "#     ('vectorizer', CountVectorizer(tokenizer=word_tokenize, ngram_range=(2, 3))),\n",
    "#     ('classifier', SVC())\n",
    "# ])\n",
    "\n",
    "# # Define CountVectorizer pipeline for Naive Bayes with bigrams and trigrams\n",
    "# nb_cv_ngram_pipeline = Pipeline([\n",
    "#     ('vectorizer', CountVectorizer(tokenizer=word_tokenize, ngram_range=(2, 3))),\n",
    "#     ('classifier', MultinomialNB())\n",
    "# ])\n",
    "\n",
    "# # Define CountVectorizer pipeline for Random Forest with bigrams and trigrams\n",
    "# rf_cv_ngram_pipeline = Pipeline([\n",
    "#     ('vectorizer', CountVectorizer(tokenizer=word_tokenize, ngram_range=(2, 3))),\n",
    "#     ('classifier', RandomForestClassifier())\n",
    "# ])\n",
    "\n",
    "# # Define TF-IDF vectorizer pipeline for Logistic Regression with bigrams and trigrams\n",
    "# lr_tfidf_ngram_pipeline = Pipeline([\n",
    "#     ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize, ngram_range=(2, 3))),\n",
    "#     ('classifier', LogisticRegression(max_iter=1000))\n",
    "# ])\n",
    "\n",
    "# # Define TF-IDF vectorizer pipeline for Support Vector Machine (SVM) with bigrams and trigrams\n",
    "# svm_tfidf_ngram_pipeline = Pipeline([\n",
    "#     ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize, ngram_range=(2, 3))),\n",
    "#     ('classifier', SVC())\n",
    "# ])\n",
    "\n",
    "# # Define TF-IDF vectorizer pipeline for Naive Bayes with bigrams and trigrams\n",
    "# nb_tfidf_ngram_pipeline = Pipeline([\n",
    "#     ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize, ngram_range=(2, 3))),\n",
    "#     ('classifier', MultinomialNB())\n",
    "# ])\n",
    "\n",
    "# # Define TF-IDF vectorizer pipeline for Random Forest with bigrams and trigrams\n",
    "# rf_tfidf_ngram_pipeline = Pipeline([\n",
    "#     ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize, ngram_range=(2, 3))),\n",
    "#     ('classifier', RandomForestClassifier())\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92ce3939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngrams_pipelines = [lr_cv_ngram_pipeline, svm_cv_ngram_pipeline, nb_cv_ngram_pipeline, rf_cv_ngram_pipeline,\n",
    "#                    lr_tfidf_ngram_pipeline, svm_tfidf_ngram_pipeline, nb_tfidf_ngram_pipeline, rf_tfidf_ngram_pipeline]\n",
    "\n",
    "# for pipeline in ngrams_pipelines:\n",
    "#     validation(pipeline)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d18e4d5",
   "metadata": {},
   "source": [
    "### Selected three best models\n",
    "Based on Test Accuracy and Mean K-Fold Accuracy, and similar scores in Precision and Recall:\n",
    "- 1. Tfidfvectorizer(Unigrams) + SVM\n",
    "- 2. CountVectorizer(Unigrams + Bigrams) + Logistic Regression\n",
    "- 3. TfidfVectorizer(Unigrams + Bigrams) + SVM\n",
    "\n",
    "| Measure                | Tfidfvectorizer(Unigrams) + SVM | CountVectorizer(Unigrams + Bigrams) + Logistic Regression) | TfidfVectorizer(Unigrams + Bigrams) + SVM      |\n",
    "|:-----------------------|:-------------------:|:-----------------------------:|:--------:|\n",
    "| Mean K-Fold Accuracy   | 0.7202              | 0.7237                        | 0.7103   |\n",
    "| Mean K-Fold Precision  | 0.7211              | 0.7226                        | 0.7246   |\n",
    "| Mean K-Fold Recall     | 0.7202              | 0.7237                        | 0.7103   |\n",
    "| Mean K-Fold F1-Score   | 0.7152              | 0.7219                        | 0.6950   |\n",
    "| Test Accuracy          | 0.6887              | 0.7218                        | 0.6887   |\n",
    "| Test Precision         | 0.6894              | 0.7218                        | 0.7025   |\n",
    "| Test Recall            | 0.6887              | 0.7218                        | 0.6887   |\n",
    "| Test F1-Score          | 0.6878              | 0.7216                        | 0.6812   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0173d159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define TF-IDF vectorizer pipeline for Support Vector Machine (SVM)\n",
    "svm_tfidf_pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize)),\n",
    "    ('classifier', SVC())\n",
    "])\n",
    "\n",
    "# Define CountVectorizer pipeline for Logistic Regression with n-grams (1, 2)\n",
    "lr_cv_ngram_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(tokenizer=word_tokenize, ngram_range=(1, 2))),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Define TF-IDF vectorizer pipeline for Support Vector Machine (SVM) with n-grams (1, 2)\n",
    "svm_tfidf_ngram_pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize, ngram_range=(1, 2))),\n",
    "    ('classifier', SVC())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37c10712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('vectorizer',\n",
      "                 TfidfVectorizer(tokenizer=<function word_tokenize at 0x000001D31662AAC0>)),\n",
      "                ('classifier', SVC())])\n",
      "Mean K-Fold Accuracy: 0.7201907790143084\n",
      "Mean K-Fold Precision: 0.7211328432169456\n",
      "Mean K-Fold Recall: 0.7201907790143084\n",
      "Mean K-Fold F1-Score: 0.7151659876397811\n",
      "Test Accuracy: 0.688715953307393\n",
      "Test Precision: 0.6893815277493345\n",
      "Test Recall: 0.688715953307393\n",
      "Test F1-Score: 0.6877781938361852\n",
      "\n",
      "Pipeline(steps=[('vectorizer',\n",
      "                 CountVectorizer(ngram_range=(1, 2),\n",
      "                                 tokenizer=<function word_tokenize at 0x000001D31662AAC0>)),\n",
      "                ('classifier', LogisticRegression(max_iter=1000))])\n",
      "Mean K-Fold Accuracy: 0.7236883942766295\n",
      "Mean K-Fold Precision: 0.7226287155551465\n",
      "Mean K-Fold Recall: 0.7236883942766295\n",
      "Mean K-Fold F1-Score: 0.7219093869972267\n",
      "Test Accuracy: 0.7217898832684825\n",
      "Test Precision: 0.7217965366083615\n",
      "Test Recall: 0.7217898832684825\n",
      "Test F1-Score: 0.7215714657412097\n",
      "\n",
      "Pipeline(steps=[('vectorizer',\n",
      "                 TfidfVectorizer(ngram_range=(1, 2),\n",
      "                                 tokenizer=<function word_tokenize at 0x000001D31662AAC0>)),\n",
      "                ('classifier', SVC())])\n",
      "Mean K-Fold Accuracy: 0.7103338632750397\n",
      "Mean K-Fold Precision: 0.7245600872567473\n",
      "Mean K-Fold Recall: 0.7103338632750397\n",
      "Mean K-Fold F1-Score: 0.6950501802513942\n",
      "Test Accuracy: 0.688715953307393\n",
      "Test Precision: 0.7024501751909613\n",
      "Test Recall: 0.688715953307393\n",
      "Test F1-Score: 0.6812102258263938\n"
     ]
    }
   ],
   "source": [
    "validation(svm_tfidf_pipeline)\n",
    "print()\n",
    "validation(lr_cv_ngram_pipeline)\n",
    "print()\n",
    "validation(svm_tfidf_ngram_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beb0365",
   "metadata": {},
   "source": [
    "### Enhancements\n",
    "1. NER is not used as it does not perform well, WSD on every token takes too long to train due to large corpus.\n",
    "2. Ensemble model\n",
    "3. Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5815b13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the download if you have not downloaded\n",
    "# nltk.download('maxent_ne_chunker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ab24f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import pos_tag\n",
    "from nltk.chunk import ne_chunk\n",
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd6b85e",
   "metadata": {},
   "source": [
    "### Ensemble model\n",
    "- 1. Tfidfvectorizer(Unigrams) + SVM\n",
    "- 2. TfidfVectorizer(Unigrams + Bigrams) + SVM\n",
    "- 3. CountVectorizer(Unigrams + Bigrams) + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51283040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define TF-IDF vectorizer pipeline for Support Vector Machine (SVM)\n",
    "baseline_model = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize)),\n",
    "    ('classifier', SVC())\n",
    "])\n",
    "\n",
    "# Define TF-IDF vectorizer pipeline for Support Vector Machine (SVM) with n-grams (1, 2)\n",
    "svm_model = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize, ngram_range=(1, 2))),\n",
    "    ('classifier', SVC())\n",
    "])\n",
    "\n",
    "# Define CountVectorizer pipeline for Logistic Regression with n-grams (1, 2) (WSD)\n",
    "lr_model = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(tokenizer=word_tokenize, ngram_range=(1, 2))),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99900b16",
   "metadata": {},
   "source": [
    "### Recap of Individual Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d19cfde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('vectorizer',\n",
      "                 TfidfVectorizer(tokenizer=<function word_tokenize at 0x000001D31662AAC0>)),\n",
      "                ('classifier', SVC())])\n",
      "Mean K-Fold Accuracy: 0.7201907790143084\n",
      "Mean K-Fold Precision: 0.7211328432169456\n",
      "Mean K-Fold Recall: 0.7201907790143084\n",
      "Mean K-Fold F1-Score: 0.7151659876397811\n",
      "Test Accuracy: 0.688715953307393\n",
      "Test Precision: 0.6893815277493345\n",
      "Test Recall: 0.688715953307393\n",
      "Test F1-Score: 0.6877781938361852\n",
      "\n",
      "Pipeline(steps=[('vectorizer',\n",
      "                 TfidfVectorizer(ngram_range=(1, 2),\n",
      "                                 tokenizer=<function word_tokenize at 0x000001D31662AAC0>)),\n",
      "                ('classifier', SVC())])\n",
      "Mean K-Fold Accuracy: 0.7103338632750397\n",
      "Mean K-Fold Precision: 0.7245600872567473\n",
      "Mean K-Fold Recall: 0.7103338632750397\n",
      "Mean K-Fold F1-Score: 0.6950501802513942\n",
      "Test Accuracy: 0.688715953307393\n",
      "Test Precision: 0.7024501751909613\n",
      "Test Recall: 0.688715953307393\n",
      "Test F1-Score: 0.6812102258263938\n",
      "\n",
      "Pipeline(steps=[('vectorizer',\n",
      "                 CountVectorizer(ngram_range=(1, 2),\n",
      "                                 tokenizer=<function word_tokenize at 0x000001D31662AAC0>)),\n",
      "                ('classifier', LogisticRegression(max_iter=1000))])\n",
      "Mean K-Fold Accuracy: 0.7236883942766295\n",
      "Mean K-Fold Precision: 0.7226287155551465\n",
      "Mean K-Fold Recall: 0.7236883942766295\n",
      "Mean K-Fold F1-Score: 0.7219093869972267\n",
      "Test Accuracy: 0.7217898832684825\n",
      "Test Precision: 0.7217965366083615\n",
      "Test Recall: 0.7217898832684825\n",
      "Test F1-Score: 0.7215714657412097\n",
      "\n"
     ]
    }
   ],
   "source": [
    "validation(baseline_model)\n",
    "print()\n",
    "validation(svm_model)\n",
    "print()\n",
    "validation(lr_model)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08636aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier(estimators=[('baseline',\n",
      "                              Pipeline(steps=[('vectorizer',\n",
      "                                               TfidfVectorizer(tokenizer=<function word_tokenize at 0x000001D31662AAC0>)),\n",
      "                                              ('classifier', SVC())])),\n",
      "                             ('svm',\n",
      "                              Pipeline(steps=[('vectorizer',\n",
      "                                               TfidfVectorizer(ngram_range=(1,\n",
      "                                                                            2),\n",
      "                                                               tokenizer=<function word_tokenize at 0x000001D31662AAC0>)),\n",
      "                                              ('classifier', SVC())])),\n",
      "                             ('lr',\n",
      "                              Pipeline(steps=[('vectorizer',\n",
      "                                               CountVectorizer(ngram_range=(1,\n",
      "                                                                            2),\n",
      "                                                               tokenizer=<function word_tokenize at 0x000001D31662AAC0>)),\n",
      "                                              ('classifier',\n",
      "                                               LogisticRegression(max_iter=1000))]))])\n",
      "Mean K-Fold Accuracy: 0.7189189189189189\n",
      "Mean K-Fold Precision: 0.722398147388388\n",
      "Mean K-Fold Recall: 0.7189189189189189\n",
      "Mean K-Fold F1-Score: 0.7114638417837067\n",
      "Test Accuracy: 0.7062256809338522\n",
      "Test Precision: 0.708657338505462\n",
      "Test Recall: 0.7062256809338522\n",
      "Test F1-Score: 0.7044864955205622\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Define the ensemble model using a VotingClassifier\n",
    "ensemble_model = VotingClassifier(estimators=[\n",
    "    ('baseline', baseline_model),\n",
    "    ('svm', svm_model),\n",
    "     ('lr', lr_model),\n",
    "    \n",
    "], voting='hard')\n",
    "\n",
    "validation(ensemble_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea82251",
   "metadata": {},
   "source": [
    "### Conclusion of ensemble model\n",
    "\n",
    "1. The ensemble model is 2nd best in terms of Test metrics but loses to the Logistic Regression model for all metrics.\n",
    "2. We will use the Logistic Regression model.\n",
    "\n",
    "| Measure                | Baseline (SVM) | SVM      | Logistic Regression | Ensemble  |\n",
    "|------------------------|----------------|----------|---------------------|-----------|\n",
    "| Mean K-Fold Accuracy   | 0.7202         | 0.7103   | 0.7215              | 0.7189    |\n",
    "| Mean K-Fold Precision  | 0.7211         | 0.7246   | 0.7204              | 0.7224    |\n",
    "| Mean K-Fold Recall     | 0.7202         | 0.7103   | 0.7215              | 0.7189    |\n",
    "| Mean K-Fold F1-Score   | 0.7152         | 0.6951   | 0.7193              | 0.7115    |\n",
    "| Test Accuracy          | 0.6887         | 0.6887   | 0.7335              | 0.7062    |\n",
    "| Test Precision         | 0.6894         | 0.7025   | 0.7337              | 0.7087    |\n",
    "| Test Recall            | 0.6887         | 0.6887   | 0.7335              | 0.7062    |\n",
    "| Test F1-Score          | 0.6878         | 0.6812   | 0.7331              | 0.7045    |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f331c3f",
   "metadata": {},
   "source": [
    "### Enhancement by grid search for CountVectorizer(Unigrams + Bigrams) + Logistic Regression\n",
    "We will not use the ensemble model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c24751c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0269a12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_polarity['clean_text']\n",
    "y_train = df_polarity['polarity']\n",
    "X_test = polarity_test_df['clean_text']\n",
    "y_test = polarity_test_df['polarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02b4c128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (LR): {'classifier__C': 10, 'classifier__solver': 'sag'}\n",
      "Best Score (LR): 0.7100158982511924\n",
      "Test Accuracy (LR): 0.7237354085603113\n"
     ]
    }
   ],
   "source": [
    "# Define CountVectorizer pipeline for Logistic Regression with n-grams (1, 2)\n",
    "lr_model = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(tokenizer=word_tokenize, ngram_range=(1, 2))),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Define the parameter grid for grid search for lr ngram model\n",
    "lr_param_grid = {\n",
    "    'classifier__C': [0.1, 1, 10],  # Parameters for logistic regression in lr_model\n",
    "    'classifier__solver': ['lbfgs', 'liblinear', 'newton-cg', 'sag'],  # Solver options for logistic regression in lr_model\n",
    "}\n",
    "\n",
    "# Perform grid search for logistic Regression model\n",
    "lr_grid_search = GridSearchCV(lr_model, lr_param_grid, cv=5)\n",
    "lr_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best parameters and score for SVM model\n",
    "print(\"Best Parameters (LR):\", lr_grid_search.best_params_)\n",
    "print(\"Best Score (LR):\", lr_grid_search.best_score_)\n",
    "\n",
    "# Evaluate the best model found by grid search on test data\n",
    "test_accuracy = lr_grid_search.score(X_test, y_test)\n",
    "print(\"Test Accuracy (LR):\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11de880",
   "metadata": {},
   "source": [
    "### Testing the updated LR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa75b1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('vectorizer',\n",
      "                 CountVectorizer(ngram_range=(1, 2),\n",
      "                                 tokenizer=<function word_tokenize at 0x000001D31662AAC0>)),\n",
      "                ('classifier', LogisticRegression(max_iter=1000))])\n",
      "Mean K-Fold Accuracy: 0.7236883942766295\n",
      "Mean K-Fold Precision: 0.7226287155551465\n",
      "Mean K-Fold Recall: 0.7236883942766295\n",
      "Mean K-Fold F1-Score: 0.7219093869972267\n",
      "Test Accuracy: 0.7217898832684825\n",
      "Test Precision: 0.7217965366083615\n",
      "Test Recall: 0.7217898832684825\n",
      "Test F1-Score: 0.7215714657412097\n"
     ]
    }
   ],
   "source": [
    "# Original\n",
    "lr_model = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(tokenizer=word_tokenize, ngram_range=(1, 2))),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "validation(lr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee4d538f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('vectorizer',\n",
      "                 CountVectorizer(ngram_range=(1, 2),\n",
      "                                 tokenizer=<function word_tokenize at 0x000001D31662AAC0>)),\n",
      "                ('classifier',\n",
      "                 LogisticRegression(C=10, max_iter=1000, solver='sag'))])\n",
      "Mean K-Fold Accuracy: 0.7208267090620032\n",
      "Mean K-Fold Precision: 0.7200747479463524\n",
      "Mean K-Fold Recall: 0.7208267090620032\n",
      "Mean K-Fold F1-Score: 0.7195594034537685\n",
      "Test Accuracy: 0.7237354085603113\n",
      "Test Precision: 0.7237179111281777\n",
      "Test Recall: 0.7237354085603113\n",
      "Test F1-Score: 0.7235510310268908\n"
     ]
    }
   ],
   "source": [
    "# Updated\n",
    "lr_model = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(tokenizer=word_tokenize, ngram_range=(1, 2))),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, C=10, solver='sag'))\n",
    "])\n",
    "\n",
    "validation(lr_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b9fef6",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "1. The updated model by grid search shows a slight increase performance in Test metrics but a slight decrease in performance for K-Fold metrics , this may be due to different shuffles in K-Fold used by grid search that resulted in different performance.\n",
    "2. We will use the original model as it produces results with values closer to each other for K-Fold and Test-Metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "66fc4a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 1.148392915725708 seconds\n",
      "Training size: 3145\n",
      "Training time per sample: 0.00036514878083488333 seconds\n",
      "Train samples per second: 2738.609718793475\n",
      "\n",
      "Inference time: 0.07500004768371582 seconds\n",
      "Inference size: 514\n",
      "Inference time per sample: 0.00014591448965703467 seconds\n",
      "Inference samples per second: 6853.328976104116\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pickle\n",
    "\n",
    "# Original\n",
    "lr_model = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(tokenizer=word_tokenize, ngram_range=(1, 2))),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the ensemble model\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# End the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Save the model to a file\n",
    "with open('polarity_model.pkl', 'wb') as f:\n",
    "    pickle.dump(lr_model, f)\n",
    "    \n",
    "# Calculate the training time\n",
    "training_time = end_time - start_time\n",
    "\n",
    "print(\"Training time:\", training_time, \"seconds\")\n",
    "print(\"Training size:\", len(X_train))\n",
    "print(\"Training time per sample:\", training_time/len(X_train), \"seconds\")\n",
    "print(\"Train samples per second:\", len(X_train) / training_time)\n",
    "print()\n",
    "\n",
    "# Start the timer for inference\n",
    "start_time = time.time()\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = lr_model.predict(X_test)\n",
    "\n",
    "# End the timer for inference\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the inference time\n",
    "inference_time = end_time - start_time\n",
    "print(\"Inference time:\", inference_time, \"seconds\")\n",
    "print(\"Inference size:\", len(X_test))\n",
    "print(\"Inference time per sample:\", inference_time / len(X_test), \"seconds\")\n",
    "print(\"Inference samples per second:\", len(X_test) / inference_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "91a77fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vaccine is bad, do not take it. Negative\n",
      "The vaccine is good for everyone even though it hurts badly, please take it. Positive\n"
     ]
    }
   ],
   "source": [
    "# Later, when you want to use the model for prediction:\n",
    "import re\n",
    "import contractions\n",
    "import emoji\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pickle\n",
    "\n",
    "# Load the model from the file\n",
    "with open('polarity_model.pkl', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "\n",
    "# Decode output:\n",
    "def decode(predictions):\n",
    "    if predictions[0] == 0:\n",
    "           return 'Negative'\n",
    "    else:\n",
    "        return 'Positive'\n",
    "    \n",
    "# Preprocess tweet    \n",
    "def preprocess(text):\n",
    "    # Step 1: Expand contractions\n",
    "    text = contractions.fix(text)\n",
    "    # Step 2: Map emojis into its word meaning\n",
    "    text = emoji.demojize(text)\n",
    "    # Step 3: Remove mentions, hashtags, numbers and links\n",
    "    pattern = r'@[A-Za-z0-9_]+|#[A-Za-z0-9]+|\\d+|https?://\\S+|[^\\w\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    # put text to lowercase\n",
    "    text = text.lower() \n",
    "    # Step 4: Lemmatize words\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    words = text.split()\n",
    "    words = [wordnet_lemmatizer.lemmatize(word, pos=\"v\") for word in words]\n",
    "    text = ' '.join(words)\n",
    "    return text\n",
    "\n",
    "# Make predictions using the loaded model\n",
    "tweet_1 = 'The vaccine is bad, do not take it.'\n",
    "tweet = preprocess(tweet_1)\n",
    "predictions = loaded_model.predict([tweet])\n",
    "print(tweet_1, decode(predictions) )\n",
    "\n",
    "tweet_2 = 'The vaccine is good for everyone even though it hurts badly, please take it.'\n",
    "tweet = preprocess(tweet_2)\n",
    "predictions = loaded_model.predict([tweet])\n",
    "print(tweet_2, decode(predictions) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ac27e5",
   "metadata": {},
   "source": [
    "### Time tests for scalability\n",
    "1. Training time\n",
    "2. Inference time\n",
    "\n",
    "| Metric                        | Value                        |\n",
    "|:------------------------------|:-----------------------------|\n",
    "| Training time (s)             | 1.1484                       |\n",
    "| Training size                 | 3145                         |\n",
    "| Training time per sample (s)  | 0.0003651                    |\n",
    "| Train samples per second      | 2738.61                      |\n",
    "| Inference time (s)            | 0.0750                       |\n",
    "| Inference size                | 514                          |\n",
    "| Inference time per sample (s) | 0.0001459                    |\n",
    "| Inference samples per second  | 6853.33                      |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "It is very scalable with extremely fast training and inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f096207f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
