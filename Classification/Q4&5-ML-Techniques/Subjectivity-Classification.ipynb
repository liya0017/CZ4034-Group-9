{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d104707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca348955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install contractions\n",
    "# !pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20cc9b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>1376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neutral</th>\n",
       "      <td>3853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>1769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          full_text\n",
       "label              \n",
       "Negative       1376\n",
       "Neutral        3853\n",
       "Positive       1769"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "df = df[['full_text', 'Sentiment Analysis (Label)']]\n",
    "df.rename(columns = {'Sentiment Analysis (Label)': 'label'}, inplace = True)\n",
    "df.dropna(inplace=True)\n",
    "df.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa9877d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subjectivity</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              full_text\n",
       "subjectivity           \n",
       "0                  3853\n",
       "1                  3145"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_mapping = {'Negative': 1, 'Positive': 1, 'Neutral': 0}\n",
    "df['subjectivity'] = df['label'].map(label_mapping)\n",
    "df_subjectivity = df[['full_text','subjectivity']]\n",
    "df_subjectivity.groupby('subjectivity').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e44316a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thinking about a conspiraboomer paying some CO...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@aja9696 @civillibertari2 @POTUS That's litera...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@POTUS I have a question Mr Presidente  If I g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@ziggystar18 @corybernardi Ironically, yes, be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@dysclinic And many become worse after covid v...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  subjectivity\n",
       "0  Thinking about a conspiraboomer paying some CO...             1\n",
       "1  @aja9696 @civillibertari2 @POTUS That's litera...             1\n",
       "2  @POTUS I have a question Mr Presidente  If I g...             1\n",
       "3  @ziggystar18 @corybernardi Ironically, yes, be...             1\n",
       "4  @dysclinic And many become worse after covid v...             1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subjectivity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b3ac6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"eval.csv\")\n",
    "test_df = test_df[['full_text', 'Sentiment Analysis (Label)']]\n",
    "test_df.rename(columns = {'Sentiment Analysis (Label)': 'label'}, inplace = True)\n",
    "test_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1151bcbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subjectivity</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              full_text\n",
       "subjectivity           \n",
       "0                   486\n",
       "1                   514"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_mapping = {'Negative': 1, 'Positive': 1, 'Neutral': 0}\n",
    "test_df['subjectivity'] = test_df['label'].map(label_mapping)\n",
    "subjectivity_test_df = test_df[['full_text','subjectivity']]\n",
    "subjectivity_test_df.groupby('subjectivity').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ef3752",
   "metadata": {},
   "source": [
    "### Preprocessing Tweets\n",
    "\n",
    "We will be using these commonly used ways to pre-process tweets\n",
    "\n",
    "1. Expand contractions\n",
    "2. Map emojis into its word meaning\n",
    "3. Remove mentions(@), hashtags(#), punctuations and numbers as we prioritise sentiment from the text\n",
    "4. Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d35cad5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import contractions\n",
    "import emoji\n",
    "import nltk\n",
    "# Download if u havent\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('punkt')\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5d43f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i cannot believe it be of the clock i will be home soon party_popper\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "\n",
    "    # Step 1: Expand contractions\n",
    "    text = contractions.fix(text)\n",
    "    \n",
    "    # Step 2: Map emojis into its word meaning\n",
    "    text = emoji.demojize(text)\n",
    "    \n",
    "    # Step 3: Remove mentions, hashtags, numbers and links\n",
    "    pattern = r'@[A-Za-z0-9_]+|#[A-Za-z0-9]+|\\d+|https?://\\S+|[^\\w\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    # put text to lowercase\n",
    "    text = text.lower() \n",
    "\n",
    "    \n",
    "    # Step 4: Lemmatize words\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    words = text.split()\n",
    "    words = [wordnet_lemmatizer.lemmatize(word, pos=\"v\") for word in words]\n",
    "    text = ' '.join(words)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Example usage:\n",
    "tweet = \"@username #happybirthday! I can't believe it's 5 o'clock. 123 I'll be home soon https://facebook.com 🎉\"\n",
    "cleaned_tweet = clean_text(tweet)\n",
    "print(cleaned_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b83fa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subjectivity['clean_text'] = df_subjectivity['full_text'].apply(clean_text)\n",
    "subjectivity_test_df['clean_text'] = subjectivity_test_df['full_text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf973c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thinking about a conspiraboomer paying some CO...</td>\n",
       "      <td>1</td>\n",
       "      <td>think about a conspiraboomer pay some covidpos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@aja9696 @civillibertari2 @POTUS That's litera...</td>\n",
       "      <td>1</td>\n",
       "      <td>that be literally what the vaers be a cdc repo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@POTUS I have a question Mr Presidente  If I g...</td>\n",
       "      <td>1</td>\n",
       "      <td>i have a question mr presidente if i get the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@ziggystar18 @corybernardi Ironically, yes, be...</td>\n",
       "      <td>1</td>\n",
       "      <td>ironically yes because australia have a good p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@dysclinic And many become worse after covid v...</td>\n",
       "      <td>1</td>\n",
       "      <td>and many become worse after covid vaccines muc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  subjectivity  \\\n",
       "0  Thinking about a conspiraboomer paying some CO...             1   \n",
       "1  @aja9696 @civillibertari2 @POTUS That's litera...             1   \n",
       "2  @POTUS I have a question Mr Presidente  If I g...             1   \n",
       "3  @ziggystar18 @corybernardi Ironically, yes, be...             1   \n",
       "4  @dysclinic And many become worse after covid v...             1   \n",
       "\n",
       "                                          clean_text  \n",
       "0  think about a conspiraboomer pay some covidpos...  \n",
       "1  that be literally what the vaers be a cdc repo...  \n",
       "2  i have a question mr presidente if i get the c...  \n",
       "3  ironically yes because australia have a good p...  \n",
       "4  and many become worse after covid vaccines muc...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subjectivity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81cbe70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Here is today’s Idaho COVID-19 vaccine data at...</td>\n",
       "      <td>0</td>\n",
       "      <td>here be todays idaho covid vaccine data at a g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Health care worker dies after second dose of C...</td>\n",
       "      <td>1</td>\n",
       "      <td>health care worker die after second dose of co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boris Johnson: Emergency Services to receive C...</td>\n",
       "      <td>0</td>\n",
       "      <td>boris johnson emergency service to receive cov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Think about it.... The same Liberal government...</td>\n",
       "      <td>1</td>\n",
       "      <td>think about it the same liberal government tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South Africa receives its first anti-Covid vac...</td>\n",
       "      <td>0</td>\n",
       "      <td>south africa receive its first anticovid vaccines</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  subjectivity  \\\n",
       "0  Here is today’s Idaho COVID-19 vaccine data at...             0   \n",
       "1  Health care worker dies after second dose of C...             1   \n",
       "2  Boris Johnson: Emergency Services to receive C...             0   \n",
       "3  Think about it.... The same Liberal government...             1   \n",
       "4  South Africa receives its first anti-Covid vac...             0   \n",
       "\n",
       "                                          clean_text  \n",
       "0  here be todays idaho covid vaccine data at a g...  \n",
       "1  health care worker die after second dose of co...  \n",
       "2  boris johnson emergency service to receive cov...  \n",
       "3  think about it the same liberal government tha...  \n",
       "4  south africa receive its first anticovid vaccines  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjectivity_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b67c5458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47674e4",
   "metadata": {},
   "source": [
    "### Subjectivity Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43c6dfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def validation(pipeline):\n",
    "    \n",
    "    print(pipeline)\n",
    "    \n",
    "    # Initialize lists to store evaluation metrics\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "\n",
    "    # K-Fold Cross Validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(df_subjectivity)):\n",
    "            X_train_fold, X_val_fold = df_subjectivity['clean_text'].iloc[train_index], df_subjectivity['clean_text'].iloc[val_index]\n",
    "            y_train_fold, y_val_fold = df_subjectivity['subjectivity'].iloc[train_index], df_subjectivity['subjectivity'].iloc[val_index]\n",
    "\n",
    "            pipeline.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "            # Get predictions on validation fold\n",
    "            predictions = pipeline.predict(X_val_fold)\n",
    "\n",
    "            # Compute accuracy for this fold\n",
    "            fold_accuracy = accuracy_score(y_val_fold, predictions)\n",
    "            accuracies.append(fold_accuracy)\n",
    "            \n",
    "            # Compute precision, recall, and F1-score for this fold\n",
    "            fold_report = classification_report(y_val_fold, predictions, output_dict=True)\n",
    "\n",
    "            # Append precision, recall, and F1-score to respective lists\n",
    "            precisions.append(fold_report['weighted avg']['precision'])\n",
    "            recalls.append(fold_report['weighted avg']['recall'])\n",
    "            f1_scores.append(fold_report['weighted avg']['f1-score'])\n",
    "\n",
    "    # Calculate the mean accuracy, precision, recall, and F1-score across all folds\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    mean_precision = np.mean(precisions)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    mean_f1_score = np.mean(f1_scores)\n",
    "    \n",
    "    # Test against test set\n",
    "    pipeline.fit(df_subjectivity['clean_text'], df_subjectivity['subjectivity'])\n",
    "    \n",
    "    # Get predictions on test set\n",
    "    predictions = pipeline.predict(subjectivity_test_df['clean_text'])\n",
    "    \n",
    "    # Compute accuracy for test set\n",
    "    test_accuracy = accuracy_score(subjectivity_test_df['subjectivity'], predictions)\n",
    "\n",
    "    # Compute precision, recall, and F1-score for test set\n",
    "    test_report = classification_report(subjectivity_test_df['subjectivity'], predictions, output_dict=True)\n",
    "\n",
    "    print(\"Mean K-Fold Accuracy:\", mean_accuracy)\n",
    "    print(\"Mean K-Fold Precision:\", mean_precision)\n",
    "    print(\"Mean K-Fold Recall:\", mean_recall)\n",
    "    print(\"Mean K-Fold F1-Score:\", mean_f1_score)\n",
    "    \n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "    print(\"Test Precision:\", test_report['weighted avg']['precision'])\n",
    "    print(\"Test Recall:\", test_report['weighted avg']['recall'])\n",
    "    print(\"Test F1-Score:\", test_report['weighted avg']['f1-score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0790d9fd",
   "metadata": {},
   "source": [
    "### Pipelines using unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5dfddd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define count vectorizer pipeline for Logistic Regression\n",
    "lr_cv_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(tokenizer=word_tokenize)),  # Use NLTK's word_tokenize function\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Define count vectorizer pipeline for Support Vector Machine (SVM)\n",
    "svm_cv_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(tokenizer=word_tokenize)),  # Use NLTK's word_tokenize function\n",
    "    ('classifier', SVC())\n",
    "])\n",
    "\n",
    "# Define count vectorizer pipeline for Naive Bayes\n",
    "nb_cv_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(tokenizer=word_tokenize)),  # Use NLTK's word_tokenize function\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Define count vectorizer pipeline for Random Forest\n",
    "rf_cv_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(tokenizer=word_tokenize)),  # Use NLTK's word_tokenize function\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Define TF-IDF vectorizer pipeline for Logistic Regression\n",
    "lr_tfidf_pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize)),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Define TF-IDF vectorizer pipeline for Support Vector Machine (SVM)\n",
    "svm_tfidf_pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize)),\n",
    "    ('classifier', SVC())\n",
    "])\n",
    "\n",
    "# Define TF-IDF vectorizer pipeline for Naive Bayes\n",
    "nb_tfidf_pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize)),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Define TF-IDF vectorizer pipeline for Random Forest\n",
    "rf_tfidf_pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize)),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f73d4421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('vectorizer',\n",
      "                 CountVectorizer(tokenizer=<function word_tokenize at 0x000002C204762340>)),\n",
      "                ('classifier', LogisticRegression(max_iter=1000))])\n",
      "Mean K-Fold Accuracy: 0.6854849382211784\n",
      "Mean K-Fold Precision: 0.684201785085691\n",
      "Mean K-Fold Recall: 0.6854849382211784\n",
      "Mean K-Fold F1-Score: 0.683599645582267\n",
      "Test Accuracy: 0.657\n",
      "Test Precision: 0.6656068159600051\n",
      "Test Recall: 0.657\n",
      "Test F1-Score: 0.6544575120818843\n",
      "\n",
      "Pipeline(steps=[('vectorizer',\n",
      "                 CountVectorizer(tokenizer=<function word_tokenize at 0x000002C204762340>)),\n",
      "                ('classifier', SVC())])\n",
      "Mean K-Fold Accuracy: 0.6834831001735934\n",
      "Mean K-Fold Precision: 0.6829064960651245\n",
      "Mean K-Fold Recall: 0.6834831001735934\n",
      "Mean K-Fold F1-Score: 0.6801079130598799\n",
      "Test Accuracy: 0.665\n",
      "Test Precision: 0.6787288760743747\n",
      "Test Recall: 0.665\n",
      "Test F1-Score: 0.660746355025606\n",
      "\n",
      "Pipeline(steps=[('vectorizer',\n",
      "                 CountVectorizer(tokenizer=<function word_tokenize at 0x000002C204762340>)),\n",
      "                ('classifier', MultinomialNB())])\n",
      "Mean K-Fold Accuracy: 0.6801990197079546\n",
      "Mean K-Fold Precision: 0.689655085036929\n",
      "Mean K-Fold Recall: 0.6801990197079546\n",
      "Mean K-Fold F1-Score: 0.6808969650055499\n",
      "Test Accuracy: 0.679\n",
      "Test Precision: 0.6791318882951911\n",
      "Test Recall: 0.679\n",
      "Test F1-Score: 0.6784108401345081\n",
      "\n",
      "Pipeline(steps=[('vectorizer',\n",
      "                 CountVectorizer(tokenizer=<function word_tokenize at 0x000002C204762340>)),\n",
      "                ('classifier', RandomForestClassifier())])\n",
      "Mean K-Fold Accuracy: 0.6854826917185746\n",
      "Mean K-Fold Precision: 0.6846967213993185\n",
      "Mean K-Fold Recall: 0.6854826917185746\n",
      "Mean K-Fold F1-Score: 0.6841048594828152\n",
      "Test Accuracy: 0.657\n",
      "Test Precision: 0.6644027174381254\n",
      "Test Recall: 0.657\n",
      "Test F1-Score: 0.6549177675679746\n",
      "\n",
      "Pipeline(steps=[('vectorizer',\n",
      "                 TfidfVectorizer(tokenizer=<function word_tokenize at 0x000002C204762340>)),\n",
      "                ('classifier', LogisticRegression(max_iter=1000))])\n",
      "Mean K-Fold Accuracy: 0.6899147350148065\n",
      "Mean K-Fold Precision: 0.6892420830589006\n",
      "Mean K-Fold Recall: 0.6899147350148065\n",
      "Mean K-Fold F1-Score: 0.687304330929749\n",
      "Test Accuracy: 0.688\n",
      "Test Precision: 0.6975497188834479\n",
      "Test Recall: 0.688\n",
      "Test F1-Score: 0.6857418939783839\n",
      "\n",
      "Pipeline(steps=[('vectorizer',\n",
      "                 TfidfVectorizer(tokenizer=<function word_tokenize at 0x000002C204762340>)),\n",
      "                ('classifier', SVC())])\n",
      "Mean K-Fold Accuracy: 0.6936307566629225\n",
      "Mean K-Fold Precision: 0.693164464310227\n",
      "Mean K-Fold Recall: 0.6936307566629225\n",
      "Mean K-Fold F1-Score: 0.6916589979537864\n",
      "Test Accuracy: 0.678\n",
      "Test Precision: 0.6855648584905659\n",
      "Test Recall: 0.678\n",
      "Test F1-Score: 0.6761963066025803\n",
      "\n",
      "Pipeline(steps=[('vectorizer',\n",
      "                 TfidfVectorizer(tokenizer=<function word_tokenize at 0x000002C204762340>)),\n",
      "                ('classifier', MultinomialNB())])\n",
      "Mean K-Fold Accuracy: 0.6882019810068416\n",
      "Mean K-Fold Precision: 0.6887196701824576\n",
      "Mean K-Fold Recall: 0.6882019810068416\n",
      "Mean K-Fold F1-Score: 0.6871979339927357\n",
      "Test Accuracy: 0.664\n",
      "Test Precision: 0.6675203562956867\n",
      "Test Recall: 0.664\n",
      "Test F1-Score: 0.6633542187199691\n",
      "\n",
      "Pipeline(steps=[('vectorizer',\n",
      "                 TfidfVectorizer(tokenizer=<function word_tokenize at 0x000002C204762340>)),\n",
      "                ('classifier', RandomForestClassifier())])\n",
      "Mean K-Fold Accuracy: 0.6784835086286123\n",
      "Mean K-Fold Precision: 0.6775594114756422\n",
      "Mean K-Fold Recall: 0.6784835086286123\n",
      "Mean K-Fold F1-Score: 0.6762415146505653\n",
      "Test Accuracy: 0.647\n",
      "Test Precision: 0.6592628629369865\n",
      "Test Recall: 0.647\n",
      "Test F1-Score: 0.6426792207883981\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv_pipelines = [lr_cv_pipeline, svm_cv_pipeline, nb_cv_pipeline, rf_cv_pipeline,\n",
    "                lr_tfidf_pipeline, svm_tfidf_pipeline, nb_tfidf_pipeline, rf_tfidf_pipeline]\n",
    "\n",
    "for pipeline in cv_pipelines:\n",
    "    validation(pipeline)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0b11d4",
   "metadata": {},
   "source": [
    "### Pipelines using n-grams(1,2) : Unigrams + Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8feca4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CountVectorizer pipeline for Logistic Regression with n-grams (1, 2)\n",
    "lr_cv_ngram_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(tokenizer=word_tokenize, ngram_range=(1, 2))),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Define CountVectorizer pipeline for Support Vector Machine (SVM) with n-grams (1, 2)\n",
    "svm_cv_ngram_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(tokenizer=word_tokenize, ngram_range=(1, 2))),\n",
    "    ('classifier', SVC())\n",
    "])\n",
    "\n",
    "# Define CountVectorizer pipeline for Naive Bayes with n-grams (1, 2)\n",
    "nb_cv_ngram_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(tokenizer=word_tokenize, ngram_range=(1, 2))),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Define CountVectorizer pipeline for Random Forest with n-grams (1, 2)\n",
    "rf_cv_ngram_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(tokenizer=word_tokenize, ngram_range=(1, 2))),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Define TF-IDF vectorizer pipeline for Logistic Regression with n-grams (1, 2)\n",
    "lr_tfidf_ngram_pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize, ngram_range=(1, 2))),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Define TF-IDF vectorizer pipeline for Support Vector Machine (SVM) with n-grams (1, 2)\n",
    "svm_tfidf_ngram_pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize, ngram_range=(1, 2))),\n",
    "    ('classifier', SVC())\n",
    "])\n",
    "\n",
    "# Define TF-IDF vectorizer pipeline for Naive Bayes with n-grams (1, 2)\n",
    "nb_tfidf_ngram_pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize, ngram_range=(1, 2))),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Define TF-IDF vectorizer pipeline for Random Forest with n-grams (1, 2)\n",
    "rf_tfidf_ngram_pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize, ngram_range=(1, 2))),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3cc4d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('vectorizer',\n",
      "                 CountVectorizer(ngram_range=(1, 2),\n",
      "                                 tokenizer=<function word_tokenize at 0x000002C204762340>)),\n",
      "                ('classifier', LogisticRegression(max_iter=1000))])\n",
      "Mean K-Fold Accuracy: 0.6943448381496987\n",
      "Mean K-Fold Precision: 0.6935730981523014\n",
      "Mean K-Fold Recall: 0.6943448381496987\n",
      "Mean K-Fold F1-Score: 0.6924997480130912\n",
      "Test Accuracy: 0.689\n",
      "Test Precision: 0.6970358707097526\n",
      "Test Recall: 0.689\n",
      "Test F1-Score: 0.6872099322209851\n",
      "\n",
      "Pipeline(steps=[('vectorizer',\n",
      "                 CountVectorizer(ngram_range=(1, 2),\n",
      "                                 tokenizer=<function word_tokenize at 0x000002C204762340>)),\n",
      "                ('classifier', SVC())])\n",
      "Mean K-Fold Accuracy: 0.6853424895333402\n",
      "Mean K-Fold Precision: 0.6847024652640417\n",
      "Mean K-Fold Recall: 0.6853424895333402\n",
      "Mean K-Fold F1-Score: 0.6817724509816206\n",
      "Test Accuracy: 0.681\n",
      "Test Precision: 0.6908324389971868\n",
      "Test Recall: 0.681\n",
      "Test F1-Score: 0.6785217850408549\n",
      "\n",
      "Pipeline(steps=[('vectorizer',\n",
      "                 CountVectorizer(ngram_range=(1, 2),\n",
      "                                 tokenizer=<function word_tokenize at 0x000002C204762340>)),\n",
      "                ('classifier', MultinomialNB())])\n",
      "Mean K-Fold Accuracy: 0.6884857551312162\n",
      "Mean K-Fold Precision: 0.698757620528289\n",
      "Mean K-Fold Recall: 0.6884857551312162\n",
      "Mean K-Fold F1-Score: 0.689106054148438\n",
      "Test Accuracy: 0.68\n",
      "Test Precision: 0.6807094155844157\n",
      "Test Recall: 0.68\n",
      "Test F1-Score: 0.6789047222590907\n",
      "\n",
      "Pipeline(steps=[('vectorizer',\n",
      "                 CountVectorizer(ngram_range=(1, 2),\n",
      "                                 tokenizer=<function word_tokenize at 0x000002C204762340>)),\n",
      "                ('classifier', RandomForestClassifier())])\n",
      "Mean K-Fold Accuracy: 0.677052690697437\n",
      "Mean K-Fold Precision: 0.6768035087199247\n",
      "Mean K-Fold Recall: 0.677052690697437\n",
      "Mean K-Fold F1-Score: 0.6732189662551793\n",
      "Test Accuracy: 0.652\n",
      "Test Precision: 0.6659427641945814\n",
      "Test Recall: 0.652\n",
      "Test F1-Score: 0.6471704192546583\n",
      "\n",
      "Pipeline(steps=[('vectorizer',\n",
      "                 TfidfVectorizer(ngram_range=(1, 2),\n",
      "                                 tokenizer=<function word_tokenize at 0x000002C204762340>)),\n",
      "                ('classifier', LogisticRegression(max_iter=1000))])\n",
      "Mean K-Fold Accuracy: 0.6909158582661086\n",
      "Mean K-Fold Precision: 0.6903853121943606\n",
      "Mean K-Fold Recall: 0.6909158582661086\n",
      "Mean K-Fold F1-Score: 0.690126720291567\n",
      "Test Accuracy: 0.682\n",
      "Test Precision: 0.6861632323232323\n",
      "Test Recall: 0.682\n",
      "Test F1-Score: 0.6812663772248834\n",
      "\n",
      "Pipeline(steps=[('vectorizer',\n",
      "                 TfidfVectorizer(ngram_range=(1, 2),\n",
      "                                 tokenizer=<function word_tokenize at 0x000002C204762340>)),\n",
      "                ('classifier', SVC())])\n",
      "Mean K-Fold Accuracy: 0.6904869804962729\n",
      "Mean K-Fold Precision: 0.6901867581233968\n",
      "Mean K-Fold Recall: 0.6904869804962729\n",
      "Mean K-Fold F1-Score: 0.6899231592479561\n",
      "Test Accuracy: 0.676\n",
      "Test Precision: 0.6794473039215686\n",
      "Test Recall: 0.676\n",
      "Test F1-Score: 0.675435732158943\n",
      "\n",
      "Pipeline(steps=[('vectorizer',\n",
      "                 TfidfVectorizer(ngram_range=(1, 2),\n",
      "                                 tokenizer=<function word_tokenize at 0x000002C204762340>)),\n",
      "                ('classifier', MultinomialNB())])\n",
      "Mean K-Fold Accuracy: 0.6920588175227202\n",
      "Mean K-Fold Precision: 0.6928177228610272\n",
      "Mean K-Fold Recall: 0.6920588175227202\n",
      "Mean K-Fold F1-Score: 0.688922052281395\n",
      "Test Accuracy: 0.67\n",
      "Test Precision: 0.6799357445680976\n",
      "Test Recall: 0.67\n",
      "Test F1-Score: 0.6672548585594759\n",
      "\n",
      "Pipeline(steps=[('vectorizer',\n",
      "                 TfidfVectorizer(ngram_range=(1, 2),\n",
      "                                 tokenizer=<function word_tokenize at 0x000002C204762340>)),\n",
      "                ('classifier', RandomForestClassifier())])\n",
      "Mean K-Fold Accuracy: 0.6756246298376392\n",
      "Mean K-Fold Precision: 0.6745411310845588\n",
      "Mean K-Fold Recall: 0.6756246298376392\n",
      "Mean K-Fold F1-Score: 0.6736174290026771\n",
      "Test Accuracy: 0.668\n",
      "Test Precision: 0.6755828071959199\n",
      "Test Recall: 0.668\n",
      "Test F1-Score: 0.6660371441424073\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ngrams_pipelines = [lr_cv_ngram_pipeline, svm_cv_ngram_pipeline, nb_cv_ngram_pipeline, rf_cv_ngram_pipeline,\n",
    "                   lr_tfidf_ngram_pipeline, svm_tfidf_ngram_pipeline, nb_tfidf_ngram_pipeline, rf_tfidf_ngram_pipeline]\n",
    "\n",
    "for pipeline in ngrams_pipelines:\n",
    "    validation(pipeline)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5e5150",
   "metadata": {},
   "source": [
    "### Pipelines using n-grams(2,2) : Bigrams (Tried, performs poorly and took a long time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19b1753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define CountVectorizer pipeline for Logistic Regression with bigrams only\n",
    "# lr_cv_ngram_pipeline = Pipeline([\n",
    "#     ('vectorizer', CountVectorizer(tokenizer=word_tokenize, ngram_range=(2, 2))),\n",
    "#     ('classifier', LogisticRegression(max_iter=1000))\n",
    "# ])\n",
    "\n",
    "# # Define CountVectorizer pipeline for Support Vector Machine (SVM) with bigrams only\n",
    "# svm_cv_ngram_pipeline = Pipeline([\n",
    "#     ('vectorizer', CountVectorizer(tokenizer=word_tokenize, ngram_range=(2, 2))),\n",
    "#     ('classifier', SVC())\n",
    "# ])\n",
    "\n",
    "# # Define CountVectorizer pipeline for Naive Bayes with bigrams only\n",
    "# nb_cv_ngram_pipeline = Pipeline([\n",
    "#     ('vectorizer', CountVectorizer(tokenizer=word_tokenize, ngram_range=(2, 2))),\n",
    "#     ('classifier', MultinomialNB())\n",
    "# ])\n",
    "\n",
    "# # Define CountVectorizer pipeline for Random Forest with bigrams only\n",
    "# rf_cv_ngram_pipeline = Pipeline([\n",
    "#     ('vectorizer', CountVectorizer(tokenizer=word_tokenize, ngram_range=(2, 2))),\n",
    "#     ('classifier', RandomForestClassifier())\n",
    "# ])\n",
    "\n",
    "# # Define TF-IDF vectorizer pipeline for Logistic Regression with bigrams only\n",
    "# lr_tfidf_ngram_pipeline = Pipeline([\n",
    "#     ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize, ngram_range=(2, 2))),\n",
    "#     ('classifier', LogisticRegression(max_iter=1000))\n",
    "# ])\n",
    "\n",
    "# # Define TF-IDF vectorizer pipeline for Support Vector Machine (SVM) with bigrams only\n",
    "# svm_tfidf_ngram_pipeline = Pipeline([\n",
    "#     ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize, ngram_range=(2, 2))),\n",
    "#     ('classifier', SVC())\n",
    "# ])\n",
    "\n",
    "# # Define TF-IDF vectorizer pipeline for Naive Bayes with bigrams only\n",
    "# nb_tfidf_ngram_pipeline = Pipeline([\n",
    "#     ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize, ngram_range=(2, 2))),\n",
    "#     ('classifier', MultinomialNB())\n",
    "# ])\n",
    "\n",
    "# # Define TF-IDF vectorizer pipeline for Random Forest with bigrams only\n",
    "# rf_tfidf_ngram_pipeline = Pipeline([\n",
    "#     ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize, ngram_range=(2, 2))),\n",
    "#     ('classifier', RandomForestClassifier())\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c68f2c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngrams_pipelines = [lr_cv_ngram_pipeline, svm_cv_ngram_pipeline, nb_cv_ngram_pipeline, rf_cv_ngram_pipeline,\n",
    "#                    lr_tfidf_ngram_pipeline, svm_tfidf_ngram_pipeline, nb_tfidf_ngram_pipeline, rf_tfidf_ngram_pipeline]\n",
    "\n",
    "# for pipeline in ngrams_pipelines:\n",
    "#     validation(pipeline)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb485109",
   "metadata": {},
   "source": [
    "### Pipelines using n-grams(2,3) : Bigrams + Trigrams (Tried, performs poorly and took a long time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aece0910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define CountVectorizer pipeline for Logistic Regression with bigrams and trigrams\n",
    "# lr_cv_ngram_pipeline = Pipeline([\n",
    "#     ('vectorizer', CountVectorizer(tokenizer=word_tokenize, ngram_range=(2, 3))),\n",
    "#     ('classifier', LogisticRegression(max_iter=1000))\n",
    "# ])\n",
    "\n",
    "# # Define CountVectorizer pipeline for Support Vector Machine (SVM) with bigrams and trigrams\n",
    "# svm_cv_ngram_pipeline = Pipeline([\n",
    "#     ('vectorizer', CountVectorizer(tokenizer=word_tokenize, ngram_range=(2, 3))),\n",
    "#     ('classifier', SVC())\n",
    "# ])\n",
    "\n",
    "# # Define CountVectorizer pipeline for Naive Bayes with bigrams and trigrams\n",
    "# nb_cv_ngram_pipeline = Pipeline([\n",
    "#     ('vectorizer', CountVectorizer(tokenizer=word_tokenize, ngram_range=(2, 3))),\n",
    "#     ('classifier', MultinomialNB())\n",
    "# ])\n",
    "\n",
    "# # Define CountVectorizer pipeline for Random Forest with bigrams and trigrams\n",
    "# rf_cv_ngram_pipeline = Pipeline([\n",
    "#     ('vectorizer', CountVectorizer(tokenizer=word_tokenize, ngram_range=(2, 3))),\n",
    "#     ('classifier', RandomForestClassifier())\n",
    "# ])\n",
    "\n",
    "# # Define TF-IDF vectorizer pipeline for Logistic Regression with bigrams and trigrams\n",
    "# lr_tfidf_ngram_pipeline = Pipeline([\n",
    "#     ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize, ngram_range=(2, 3))),\n",
    "#     ('classifier', LogisticRegression(max_iter=1000))\n",
    "# ])\n",
    "\n",
    "# # Define TF-IDF vectorizer pipeline for Support Vector Machine (SVM) with bigrams and trigrams\n",
    "# svm_tfidf_ngram_pipeline = Pipeline([\n",
    "#     ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize, ngram_range=(2, 3))),\n",
    "#     ('classifier', SVC())\n",
    "# ])\n",
    "\n",
    "# # Define TF-IDF vectorizer pipeline for Naive Bayes with bigrams and trigrams\n",
    "# nb_tfidf_ngram_pipeline = Pipeline([\n",
    "#     ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize, ngram_range=(2, 3))),\n",
    "#     ('classifier', MultinomialNB())\n",
    "# ])\n",
    "\n",
    "# # Define TF-IDF vectorizer pipeline for Random Forest with bigrams and trigrams\n",
    "# rf_tfidf_ngram_pipeline = Pipeline([\n",
    "#     ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize, ngram_range=(2, 3))),\n",
    "#     ('classifier', RandomForestClassifier())\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92ce3939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngrams_pipelines = [lr_cv_ngram_pipeline, svm_cv_ngram_pipeline, nb_cv_ngram_pipeline, rf_cv_ngram_pipeline,\n",
    "#                    lr_tfidf_ngram_pipeline, svm_tfidf_ngram_pipeline, nb_tfidf_ngram_pipeline, rf_tfidf_ngram_pipeline]\n",
    "\n",
    "# for pipeline in ngrams_pipelines:\n",
    "#     validation(pipeline)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d18e4d5",
   "metadata": {},
   "source": [
    "### Selected three best models\n",
    "Based on best Test Accuracy and Mean K-Fold Accuracy, and similar scores in Precision and Recall:\n",
    "- 1. TfidfVectorizer(Unigrams) + Logistic Regression\n",
    "- 2. CountVectorizer(Unigrams + Bigrams), + Logistic Regression\n",
    "- 3. TfidfVectorizer(Unigrams + Bigrams), + Logistic Regression\n",
    "\n",
    "| Measure                                                      | TfidfVectorizer Unigrams + LR  | CountVectorizer Unigrams and Bigrams + LR | TfidfVectorizer Unigrams and Bigrams + LR |\n",
    "|:-------------------------------------------------------------|:--------------------------------|:--------------------------------------------:|:-------------------------------------------:|\n",
    "| Mean K-Fold Accuracy                                         | 0.6899                          | 0.6943                                       | 0.6909                                      |\n",
    "| Mean K-Fold Precision                                       | 0.6892                          | 0.6936                                       | 0.6904                                      |\n",
    "| Mean K-Fold Recall                                          | 0.6899                          | 0.6943                                       | 0.6909                                      |\n",
    "| Mean K-Fold F1-Score                                        | 0.6873                          | 0.6925                                       | 0.6901                                      |\n",
    "| Test Accuracy                                               | 0.688                           | 0.689                                        | 0.682                                       |\n",
    "| Test Precision                                              | 0.6975                          | 0.6970                                       | 0.6862                                      |\n",
    "| Test Recall                                                 | 0.688                           | 0.689                                        | 0.682                                       |\n",
    "| Test F1-Score                                               | 0.6857                          | 0.6872                                       | 0.6813                                      |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fc7928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define TF-IDF vectorizer pipeline for Logistic Regression\n",
    "lr_tfidf_pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize)),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Define CountVectorizer pipeline for Logistic Regression with n-grams (1, 2)\n",
    "lr_cv_ngram_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(tokenizer=word_tokenize, ngram_range=(1, 2))),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Define TF-IDF vectorizer pipeline for Logistic Regression with n-grams (1, 2)\n",
    "lr_tfidf_ngram_pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize, ngram_range=(1, 2))),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07564bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('vectorizer',\n",
      "                 TfidfVectorizer(tokenizer=<function word_tokenize at 0x000002C204762340>)),\n",
      "                ('classifier', LogisticRegression(max_iter=1000))])\n",
      "Mean K-Fold Accuracy: 0.6899147350148065\n",
      "Mean K-Fold Precision: 0.6892420830589006\n",
      "Mean K-Fold Recall: 0.6899147350148065\n",
      "Mean K-Fold F1-Score: 0.687304330929749\n",
      "Test Accuracy: 0.688\n",
      "Test Precision: 0.6975497188834479\n",
      "Test Recall: 0.688\n",
      "Test F1-Score: 0.6857418939783839\n",
      "\n",
      "Pipeline(steps=[('vectorizer',\n",
      "                 CountVectorizer(ngram_range=(1, 2),\n",
      "                                 tokenizer=<function word_tokenize at 0x000002C204762340>)),\n",
      "                ('classifier', LogisticRegression(max_iter=1000))])\n",
      "Mean K-Fold Accuracy: 0.6943448381496987\n",
      "Mean K-Fold Precision: 0.6935730981523014\n",
      "Mean K-Fold Recall: 0.6943448381496987\n",
      "Mean K-Fold F1-Score: 0.6924997480130912\n",
      "Test Accuracy: 0.689\n",
      "Test Precision: 0.6970358707097526\n",
      "Test Recall: 0.689\n",
      "Test F1-Score: 0.6872099322209851\n",
      "\n",
      "Pipeline(steps=[('vectorizer',\n",
      "                 TfidfVectorizer(ngram_range=(1, 2),\n",
      "                                 tokenizer=<function word_tokenize at 0x000002C204762340>)),\n",
      "                ('classifier', LogisticRegression(max_iter=1000))])\n",
      "Mean K-Fold Accuracy: 0.6909158582661086\n",
      "Mean K-Fold Precision: 0.6903853121943606\n",
      "Mean K-Fold Recall: 0.6909158582661086\n",
      "Mean K-Fold F1-Score: 0.690126720291567\n",
      "Test Accuracy: 0.682\n",
      "Test Precision: 0.6861632323232323\n",
      "Test Recall: 0.682\n",
      "Test F1-Score: 0.6812663772248834\n"
     ]
    }
   ],
   "source": [
    "validation(lr_tfidf_pipeline)\n",
    "print()\n",
    "validation(lr_cv_ngram_pipeline)\n",
    "print()\n",
    "validation(lr_tfidf_ngram_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beb0365",
   "metadata": {},
   "source": [
    "### Enhancements\n",
    "1. NER, WSD(applied using lesk but it takes too long to train hence it is not used.)\n",
    "2. Ensemble model\n",
    "3. Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5815b13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the download if you have not downloaded\n",
    "# nltk.download('maxent_ne_chunker')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ab24f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import pos_tag\n",
    "from nltk.chunk import ne_chunk\n",
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Function for named entity recognition (NER)\n",
    "def extract_entities(text):\n",
    "    entities = []\n",
    "    for chunk in ne_chunk(pos_tag(word_tokenize(text))):\n",
    "        if hasattr(chunk, 'label'):\n",
    "            entities.append(' '.join(c[0] for c in chunk.leaves()))\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15d60af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model without innovations\n",
    "baseline_model = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize)),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Model with named entity recognition (NER)\n",
    "ner_model = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(tokenizer=lambda text: extract_entities(text))),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9320288d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('vectorizer',\n",
      "                 TfidfVectorizer(tokenizer=<function word_tokenize at 0x000002C204762340>)),\n",
      "                ('classifier', LogisticRegression(max_iter=1000))])\n",
      "Mean K-Fold Accuracy: 0.6899147350148065\n",
      "Mean K-Fold Precision: 0.6892420830589006\n",
      "Mean K-Fold Recall: 0.6899147350148065\n",
      "Mean K-Fold F1-Score: 0.687304330929749\n",
      "Test Accuracy: 0.688\n",
      "Test Precision: 0.6975497188834479\n",
      "Test Recall: 0.688\n",
      "Test F1-Score: 0.6857418939783839\n",
      "\n",
      "Pipeline(steps=[('vectorizer',\n",
      "                 TfidfVectorizer(tokenizer=<function <lambda> at 0x000002C227D34E00>)),\n",
      "                ('classifier', LogisticRegression(max_iter=1000))])\n",
      "Mean K-Fold Accuracy: 0.5505871540896559\n",
      "Mean K-Fold Precision: 0.30343878136133373\n",
      "Mean K-Fold Recall: 0.5505871540896559\n",
      "Mean K-Fold F1-Score: 0.3911644741820092\n",
      "Test Accuracy: 0.486\n",
      "Test Precision: 0.236196\n",
      "Test Recall: 0.486\n",
      "Test F1-Score: 0.3178950201884253\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "validation(baseline_model)\n",
    "print()\n",
    "validation(ner_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4615eba8",
   "metadata": {},
   "source": [
    "### Results of baseline and NER models.\n",
    "1. NER model performs poorly, it will be excluded from the ensemble model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faa89b4",
   "metadata": {},
   "source": [
    "### Ensemble model\n",
    "- 1. TfidfVectorizer(Unigrams) + Logistic Regression\n",
    "- 2. CountVectorizer(Unigrams + Bigrams), + Logistic Regression\n",
    "- 3. TfidfVectorizer(Unigrams + Bigrams), + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51283040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define TF-IDF vectorizer pipeline for Logistic Rregression\n",
    "baseline_model = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize)),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Define CountVectorizer pipeline for Logistic Rregression with n-grams (1, 2)\n",
    "lr_cv_ngram_model = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(tokenizer=word_tokenize, ngram_range=(1, 2))),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Define TF-IDF vectorizer pipeline for Logistic Regression with n-grams (1, 2)\n",
    "lr_tfidf_ngram_model = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize, ngram_range=(1, 2))),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Define the ensemble model using a VotingClassifier\n",
    "ensemble_model = VotingClassifier(estimators=[\n",
    "    ('baseline', baseline_model),\n",
    "    ('lrcv', lr_cv_ngram_model),\n",
    "    ('lrtfidf', lr_tfidf_ngram_model),\n",
    "    \n",
    "], voting='hard')  # You can change to 'soft' if you prefer soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08ed0f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('vectorizer',\n",
      "                 TfidfVectorizer(tokenizer=<function word_tokenize at 0x000002C204762340>)),\n",
      "                ('classifier', LogisticRegression(max_iter=1000))])\n",
      "Mean K-Fold Accuracy: 0.6899147350148065\n",
      "Mean K-Fold Precision: 0.6892420830589006\n",
      "Mean K-Fold Recall: 0.6899147350148065\n",
      "Mean K-Fold F1-Score: 0.687304330929749\n",
      "Test Accuracy: 0.688\n",
      "Test Precision: 0.6975497188834479\n",
      "Test Recall: 0.688\n",
      "Test F1-Score: 0.6857418939783839\n",
      "\n",
      "Pipeline(steps=[('vectorizer',\n",
      "                 CountVectorizer(ngram_range=(1, 2),\n",
      "                                 tokenizer=<function word_tokenize at 0x000002C204762340>)),\n",
      "                ('classifier', LogisticRegression(max_iter=1000))])\n",
      "Mean K-Fold Accuracy: 0.6943448381496987\n",
      "Mean K-Fold Precision: 0.6935730981523014\n",
      "Mean K-Fold Recall: 0.6943448381496987\n",
      "Mean K-Fold F1-Score: 0.6924997480130912\n",
      "Test Accuracy: 0.689\n",
      "Test Precision: 0.6970358707097526\n",
      "Test Recall: 0.689\n",
      "Test F1-Score: 0.6872099322209851\n",
      "\n",
      "Pipeline(steps=[('vectorizer',\n",
      "                 TfidfVectorizer(ngram_range=(1, 2),\n",
      "                                 tokenizer=<function word_tokenize at 0x000002C204762340>)),\n",
      "                ('classifier', LogisticRegression(max_iter=1000))])\n",
      "Mean K-Fold Accuracy: 0.6909158582661086\n",
      "Mean K-Fold Precision: 0.6903853121943606\n",
      "Mean K-Fold Recall: 0.6909158582661086\n",
      "Mean K-Fold F1-Score: 0.690126720291567\n",
      "Test Accuracy: 0.682\n",
      "Test Precision: 0.6861632323232323\n",
      "Test Recall: 0.682\n",
      "Test F1-Score: 0.6812663772248834\n",
      "\n",
      "VotingClassifier(estimators=[('baseline',\n",
      "                              Pipeline(steps=[('vectorizer',\n",
      "                                               TfidfVectorizer(tokenizer=<function word_tokenize at 0x000002C204762340>)),\n",
      "                                              ('classifier',\n",
      "                                               LogisticRegression(max_iter=1000))])),\n",
      "                             ('lrcv',\n",
      "                              Pipeline(steps=[('vectorizer',\n",
      "                                               CountVectorizer(ngram_range=(1,\n",
      "                                                                            2),\n",
      "                                                               tokenizer=<function word_tokenize at 0x000002C204762340>)),\n",
      "                                              ('classifier',\n",
      "                                               LogisticRegression(max_iter=1000))])),\n",
      "                             ('lrtfidf',\n",
      "                              Pipeline(steps=[('vectorizer',\n",
      "                                               TfidfVectorizer(ngram_range=(1,\n",
      "                                                                            2),\n",
      "                                                               tokenizer=<function word_tokenize at 0x000002C204762340>)),\n",
      "                                              ('classifier',\n",
      "                                               LogisticRegression(max_iter=1000))]))])\n",
      "Mean K-Fold Accuracy: 0.6942018788930869\n",
      "Mean K-Fold Precision: 0.6934816782715034\n",
      "Mean K-Fold Recall: 0.6942018788930869\n",
      "Mean K-Fold F1-Score: 0.6925746345029854\n",
      "Test Accuracy: 0.691\n",
      "Test Precision: 0.6987664450127877\n",
      "Test Recall: 0.691\n",
      "Test F1-Score: 0.6893161734815249\n"
     ]
    }
   ],
   "source": [
    "validation(baseline_model)\n",
    "print()\n",
    "validation(lr_cv_ngram_model)\n",
    "print()\n",
    "validation(lr_tfidf_ngram_model)\n",
    "print()\n",
    "validation(ensemble_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea82251",
   "metadata": {},
   "source": [
    "### Conclusion of ensemble model\n",
    "1. The Ensemble model has highest Test metrics and K-Fold Metrics on par with the best.\n",
    "3. This shows a good improvement compared to only using 1 model.\n",
    "\n",
    "| Measure              | Baseline (LR) | CV LR Ngrams      | TFIDF LR Ngrams     | Ensemble (Voting) |\n",
    "|:---------------------|:--------------:|:--------:|:--------:|:-----------------:|\n",
    "| Mean K-Fold Accuracy | 0.6899         | 0.6943   | 0.6909   | 0.6942            |\n",
    "| Mean K-Fold Precision| 0.6892         | 0.6936   | 0.6904   | 0.6935            |\n",
    "| Mean K-Fold Recall   | 0.6899         | 0.6943   | 0.6909   | 0.6942            |\n",
    "| Mean K-Fold F1-Score | 0.6873         | 0.6925   | 0.6901   | 0.6926            |\n",
    "| Test Accuracy        | 0.688          | 0.689    | 0.682    | 0.691             |\n",
    "| Test Precision       | 0.6975         | 0.6970   | 0.686    | 0.6988            |\n",
    "| Test Recall          | 0.688          | 0.689    | 0.682    | 0.691             |\n",
    "| Test F1-Score        | 0.6857         | 0.6872   | 0.681    | 0.6893            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f331c3f",
   "metadata": {},
   "source": [
    "### Enhancement by grid search for Logistic Regression\n",
    "As the grid search for Ensemble model takes took long, we will investigate for Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b415a38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_subjectivity['clean_text']\n",
    "y_train = df_subjectivity['subjectivity']\n",
    "X_test = subjectivity_test_df['clean_text']\n",
    "y_test = subjectivity_test_df['subjectivity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "47897e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define TF-IDF vectorizer pipeline for Logistic Rregression\n",
    "baseline_model = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize)),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Define CountVectorizer pipeline for Logistic Rregression with n-grams (1, 2)\n",
    "lr_cv_ngram_model = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(tokenizer=word_tokenize, ngram_range=(1, 2))),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Define TF-IDF vectorizer pipeline for Logistic Regression with n-grams (1, 2)\n",
    "lr_tfidf_ngram_model = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize, ngram_range=(1, 2))),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "69bee352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (LR baseline): {'classifier__C': 1, 'classifier__solver': 'lbfgs'}\n",
      "Best Score (LR baseline): 0.693770141938119\n",
      "Test Accuracy (LR baseline): 0.688\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for grid search for logistic regression model\n",
    "lr_param_grid = {\n",
    "    'classifier__C': [0.1, 1, 10],  # Parameters for logistic regression in lr_model\n",
    "    'classifier__solver': ['lbfgs', 'liblinear', 'newton-cg', 'sag'],  # Solver options for logistic regression in lr_model\n",
    "}\n",
    "\n",
    "# Perform grid search for logistic regression model with TF-IDF vectorizer\n",
    "lr_grid_search = GridSearchCV(baseline_model, lr_param_grid, cv=5)\n",
    "lr_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best parameters and score for logistic regression model with TF-IDF vectorizer\n",
    "print(\"Best Parameters (LR baseline):\", lr_grid_search.best_params_)\n",
    "print(\"Best Score (LR baseline):\", lr_grid_search.best_score_)\n",
    "\n",
    "# Evaluate the best model found by grid search on test data\n",
    "test_accuracy = lr_grid_search.score(X_test, y_test)\n",
    "print(\"Test Accuracy (LR baseline):\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ba95698f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (LR cv): {'classifier__C': 0.1, 'classifier__solver': 'lbfgs'}\n",
      "Best Score (LR cv): 0.6944837128561218\n",
      "Test Accuracy (LR cv): 0.674\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for grid search for logistic regression model\n",
    "lr_param_grid = {\n",
    "    'classifier__C': [0.1, 1, 10],  # Parameters for logistic regression in lr_model\n",
    "    'classifier__solver': ['lbfgs', 'liblinear', 'newton-cg', 'sag'],  # Solver options for logistic regression in lr_model\n",
    "}\n",
    "\n",
    "# Perform grid search for logistic regression model with TF-IDF vectorizer\n",
    "lr_grid_search = GridSearchCV(lr_cv_ngram_model, lr_param_grid, cv=5)\n",
    "lr_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best parameters and score for logistic regression model with TF-IDF vectorizer\n",
    "print(\"Best Parameters (LR cv):\", lr_grid_search.best_params_)\n",
    "print(\"Best Score (LR cv):\", lr_grid_search.best_score_)\n",
    "\n",
    "# Evaluate the best model found by grid search on test data\n",
    "test_accuracy = lr_grid_search.score(X_test, y_test)\n",
    "print(\"Test Accuracy (LR cv):\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fcb5bf0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (LR tfidf): {'classifier__C': 10, 'classifier__solver': 'lbfgs'}\n",
      "Best Score (LR tfidf): 0.6927703461656286\n",
      "Test Accuracy (LR tfidf): 0.693\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for grid search for logistic regression model\n",
    "lr_param_grid = {\n",
    "    'classifier__C': [0.1, 1, 10],  # Parameters for logistic regression in lr_model\n",
    "    'classifier__solver': ['lbfgs', 'liblinear', 'newton-cg', 'sag'],  # Solver options for logistic regression in lr_model\n",
    "}\n",
    "\n",
    "# Perform grid search for logistic regression model with TF-IDF vectorizer\n",
    "lr_grid_search = GridSearchCV(lr_tfidf_ngram_model, lr_param_grid, cv=5)\n",
    "lr_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best parameters and score for logistic regression model with TF-IDF vectorizer\n",
    "print(\"Best Parameters (LR tfidf):\", lr_grid_search.best_params_)\n",
    "print(\"Best Score (LR tfidf):\", lr_grid_search.best_score_)\n",
    "\n",
    "# Evaluate the best model found by grid search on test data\n",
    "test_accuracy = lr_grid_search.score(X_test, y_test)\n",
    "print(\"Test Accuracy (LR tfidf):\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8464f1e4",
   "metadata": {},
   "source": [
    "### Updated Ensemble Model\n",
    "\n",
    "1. We will update for lr_tfidf_ngams models only. The optimized parameters for baseline is the same as the original. As the test accuracy for lr_cv_ngrams decreased, we will not use its updated config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d4ab30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define TF-IDF vectorizer pipeline for Logistic Rregression\n",
    "baseline_model = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize)),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Define CountVectorizer pipeline for Logistic Rregression with n-grams (1, 2)\n",
    "lr_cv_ngram_model = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(tokenizer=word_tokenize, ngram_range=(1, 2))),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Define TF-IDF vectorizer pipeline for Logistic Regression with n-grams (1, 2)\n",
    "lr_tfidf_ngram_model = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(tokenizer=word_tokenize, ngram_range=(1, 2))),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, C=10, solver='lbfgs'))\n",
    "])\n",
    "\n",
    "# Define the ensemble model using a VotingClassifier\n",
    "ensemble_model = VotingClassifier(estimators=[\n",
    "    ('baseline', baseline_model),\n",
    "    ('lrcv', lr_cv_ngram_model),\n",
    "    ('lrtfidf', lr_tfidf_ngram_model),\n",
    "    \n",
    "], voting='hard')  # You can change to 'soft' if you prefer soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f1babaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier(estimators=[('baseline',\n",
      "                              Pipeline(steps=[('vectorizer',\n",
      "                                               TfidfVectorizer(tokenizer=<function word_tokenize at 0x000002C204762340>)),\n",
      "                                              ('classifier',\n",
      "                                               LogisticRegression(max_iter=1000))])),\n",
      "                             ('lrcv',\n",
      "                              Pipeline(steps=[('vectorizer',\n",
      "                                               CountVectorizer(ngram_range=(1,\n",
      "                                                                            2),\n",
      "                                                               tokenizer=<function word_tokenize at 0x000002C204762340>)),\n",
      "                                              ('classifier',\n",
      "                                               LogisticRegression(max_iter=1000))])),\n",
      "                             ('lrtfidf',\n",
      "                              Pipeline(steps=[('vectorizer',\n",
      "                                               TfidfVectorizer(ngram_range=(1,\n",
      "                                                                            2),\n",
      "                                                               tokenizer=<function word_tokenize at 0x000002C204762340>)),\n",
      "                                              ('classifier',\n",
      "                                               LogisticRegression(C=10,\n",
      "                                                                  max_iter=1000))]))])\n",
      "Mean K-Fold Accuracy: 0.7017752476258552\n",
      "Mean K-Fold Precision: 0.7012898192854609\n",
      "Mean K-Fold Recall: 0.7017752476258552\n",
      "Mean K-Fold F1-Score: 0.7009461334306133\n",
      "Test Accuracy: 0.698\n",
      "Test Precision: 0.703951412925137\n",
      "Test Recall: 0.698\n",
      "Test F1-Score: 0.6968957598306499\n"
     ]
    }
   ],
   "source": [
    "validation(ensemble_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc50f1a",
   "metadata": {},
   "source": [
    "| Measure                | Original Ensemble       | Updated Ensemble     |\n",
    "|------------------------|----------------|---------------|\n",
    "| Mean K-Fold Accuracy   | 0.6942         | 0.7018        |\n",
    "| Mean K-Fold Precision  | 0.6935         | 0.7013        |\n",
    "| Mean K-Fold Recall     | 0.6942         | 0.7018        |\n",
    "| Mean K-Fold F1-Score   | 0.6926         | 0.7009        |\n",
    "| Test Accuracy          | 0.691          | 0.698         |\n",
    "| Test Precision         | 0.6988         | 0.7039        |\n",
    "| Test Recall            | 0.691          | 0.698         |\n",
    "| Test F1-Score          | 0.6893         | 0.6969        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1882bc",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "We will choose the Updated Ensemble as there are improves in all metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "00efe665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 6.108870029449463 seconds\n",
      "Training size: 6998\n",
      "Training time per sample: 0.0008729451313874625 seconds\n",
      "Train samples per second: 1145.5473706699022\n",
      "\n",
      "Inference time: 0.3749995231628418 seconds\n",
      "Inference size: 1000\n",
      "Inference time per sample: 0.0003749995231628418 seconds\n",
      "Inference samples per second: 2666.670057512992\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pickle\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the ensemble model\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# End the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Save the model to a file\n",
    "with open('subjectivity_model.pkl', 'wb') as f:\n",
    "    pickle.dump(ensemble_model, f)\n",
    "    \n",
    "# Calculate the training time\n",
    "training_time = end_time - start_time\n",
    "\n",
    "print(\"Training time:\", training_time, \"seconds\")\n",
    "print(\"Training size:\", len(X_train))\n",
    "print(\"Training time per sample:\", training_time/len(X_train), \"seconds\")\n",
    "print(\"Train samples per second:\", len(X_train) / training_time)\n",
    "print()\n",
    "\n",
    "# Start the timer for inference\n",
    "start_time = time.time()\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = ensemble_model.predict(X_test)\n",
    "\n",
    "# End the timer for inference\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the inference time\n",
    "inference_time = end_time - start_time\n",
    "print(\"Inference time:\", inference_time, \"seconds\")\n",
    "print(\"Inference size:\", len(X_test))\n",
    "print(\"Inference time per sample:\", inference_time / len(X_test), \"seconds\")\n",
    "print(\"Inference samples per second:\", len(X_test) / inference_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "74a50155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vaccine is bad, do not take it. Opinionated\n",
      "The vaccine is good for everyone even though it hurts badly, please take it. Opinionated\n",
      "Covid vaccine is available for everyone to take for free. Neutral\n",
      "Covid vaccine uses mrna technology to combat the virus. Neutral\n"
     ]
    }
   ],
   "source": [
    "# Later, when you want to use the model for prediction:\n",
    "import re\n",
    "import contractions\n",
    "import emoji\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pickle\n",
    "\n",
    "# Load the model from the file\n",
    "with open('subjectivity_model.pkl', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "\n",
    "# Decode output:\n",
    "def decode(predictions):\n",
    "    if predictions[0] == 0:\n",
    "           return 'Neutral'\n",
    "    else:\n",
    "        return 'Opinionated'\n",
    "    \n",
    "# Preprocess tweet    \n",
    "def preprocess(text):\n",
    "    # Step 1: Expand contractions\n",
    "    text = contractions.fix(text)\n",
    "    # Step 2: Map emojis into its word meaning\n",
    "    text = emoji.demojize(text)\n",
    "    # Step 3: Remove mentions, hashtags, numbers and links\n",
    "    pattern = r'@[A-Za-z0-9_]+|#[A-Za-z0-9]+|\\d+|https?://\\S+|[^\\w\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    # put text to lowercase\n",
    "    text = text.lower() \n",
    "    # Step 4: Lemmatize words\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    words = text.split()\n",
    "    words = [wordnet_lemmatizer.lemmatize(word, pos=\"v\") for word in words]\n",
    "    text = ' '.join(words)\n",
    "    return text\n",
    "    \n",
    "# Make predictions using the loaded model\n",
    "tweet_1 = 'The vaccine is bad, do not take it.'\n",
    "tweet = preprocess(tweet_1)\n",
    "predictions = loaded_model.predict([tweet])\n",
    "print(tweet_1, decode(predictions) )\n",
    "\n",
    "tweet_2 = 'The vaccine is good for everyone even though it hurts badly, please take it.'\n",
    "tweet = preprocess(tweet_2)\n",
    "predictions = loaded_model.predict([tweet])\n",
    "print(tweet_2, decode(predictions) )\n",
    "\n",
    "tweet_3 = 'Covid vaccine is available for everyone to take for free.'\n",
    "tweet = preprocess(tweet_3)\n",
    "predictions = loaded_model.predict([tweet])\n",
    "print(tweet_3, decode(predictions) )\n",
    "\n",
    "tweet_4 = 'Covid vaccine uses mrna technology to combat the virus.'\n",
    "tweet = preprocess(tweet_4)\n",
    "predictions = loaded_model.predict([tweet])\n",
    "print(tweet_4, decode(predictions) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745bbe7e",
   "metadata": {},
   "source": [
    "### Time metrics for scalability\n",
    "1. Training time\n",
    "2. Inference time\n",
    "\n",
    "| Metric                        | Value                        |\n",
    "|:------------------------------|------------------------------|\n",
    "| Training time (s)             | 6.1089                       |\n",
    "| Training size                 | 6998                         |\n",
    "| Training time per sample (s)  | 0.0009                       |\n",
    "| Train samples per second      | 1145.5474                    |\n",
    "| Inference time (s)            | 0.3750                       |\n",
    "| Inference size                | 1000                         |\n",
    "| Inference time per sample (s) | 0.0004                       |\n",
    "| Inference samples per second  | 2666.6701                    |\n",
    "\n",
    "\n",
    "\n",
    "It is very scalable with extremely fast training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c24f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
